{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1+cu117\n",
      "2.0.2+cu117\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.functional as F\n",
    "import torchaudio.transforms as transforms\n",
    "\n",
    "import math\n",
    "\n",
    "from IPython.display import Audio\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import os\n",
    "from torchaudio.utils import download_asset\n",
    "import wave\n",
    "\n",
    "from scipy.io import wavfile\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from pathlib import Path\n",
    "import scipy.signal as sps\n",
    "from scipy.signal import butter, lfilter\n",
    "import random\n",
    "import pydub\n",
    "import uuid\n",
    "from pydub import AudioSegment, effects\n",
    "import soundfile as sf\n",
    "import shutil\n",
    "import openpyxl\n",
    "\n",
    "import xlsxwriter\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchaudio.__version__)\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1) Creating files for all data and classifications with its respective excel page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All locations\n",
    "path_clean = \"dataset_all4/clean/\"\n",
    "path_noisy = \"dataset_all4/noisy/\"\n",
    "path_0dB = \"dataset_all4/0dB/\"\n",
    "path_n3dB = \"dataset_all4/-3dB/\"\n",
    "path_n6dB = \"dataset_all4/-6dB/\"\n",
    "path_n9dB = \"dataset_all4/-9dB/\"\n",
    "path_3dB = \"dataset_all4/3dB/\"\n",
    "path_6dB = \"dataset_all4/6dB/\"\n",
    "path_9dB = \"dataset_all4/9dB/\"\n",
    "path = \"dataset_all4\"\n",
    "path_noise = \"dataset_all4/noise/\"\n",
    "path3 = path + \"/all_info.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the %s directory is created! dataset_all4\n",
      "the %s directory is created! dataset_all4\n",
      "The excel file 1 is created!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import xlsxwriter\n",
    "\n",
    "isExist = os.path.exists(path)\n",
    "if not isExist:\n",
    "   # Create a new directory because it does not exist\n",
    "   os.makedirs(path)\n",
    "   os.makedirs(path + \"/clean\")\n",
    "   os.makedirs(path + \"/noisy\")\n",
    "   os.makedirs(path + \"/0dB\")\n",
    "   os.makedirs(path + \"/-3dB\")\n",
    "   os.makedirs(path + \"/-6dB\")\n",
    "   os.makedirs(path + \"/-9dB\")\n",
    "   os.makedirs(path + \"/3dB\")\n",
    "   os.makedirs(path + \"/6dB\")\n",
    "   os.makedirs(path + \"/9dB\")\n",
    "   print(\"the %s directory is created!\", path)\n",
    "\n",
    "isExist2 = os.path.exists(path_noise)\n",
    "if not isExist:\n",
    "   # Create a new directory because it does not exist\n",
    "   os.makedirs(path_noise)\n",
    "   os.makedirs(path_noise + \"/0dB\")\n",
    "   os.makedirs(path_noise + \"/-3dB\")\n",
    "   os.makedirs(path_noise + \"/-6dB\")\n",
    "   os.makedirs(path_noise + \"/-9dB\")\n",
    "   os.makedirs(path_noise + \"/3dB\")\n",
    "   os.makedirs(path_noise + \"/6dB\")\n",
    "   os.makedirs(path_noise + \"/9dB\")\n",
    "   print(\"the %s directory is created!\", path)\n",
    "\n",
    "isExist3 = os.path.exists(path3)\n",
    "if not isExist3:\n",
    "   workbook1 = xlsxwriter.Workbook(path3)\n",
    "   worksheet1 = workbook1.add_worksheet()\n",
    "   worksheet1.write(0, 0, \"Sample Number\")\n",
    "   worksheet1.write(0, 1, \"Name\")\n",
    "   worksheet1.write(0, 2, \"Length(s)\")\n",
    "   worksheet1.write(0, 3, \"Type of Speech\")\n",
    "   worksheet1.write(0, 4, \"SNR(dB)\")\n",
    "   worksheet1.write(0, 5, \"Noise Type\")\n",
    "   worksheet1.write(0, 6, \"Noise Channel\")\n",
    "   worksheet1.write(0, 7, \"Speaker ID\")\n",
    "   worksheet1.write(0, 8, \"Passage ID\")\n",
    "   worksheet1.write(0, 9, \"Noise Start Time(s)\")\n",
    "   print(\"The excel file 1 is created!\")\n",
    "   workbook1.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2) Locations of speech and noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109\n"
     ]
    }
   ],
   "source": [
    "speech_fpath = \"speech/VCTK-Corpus/wav48/\"\n",
    "speech_file_entries = os.listdir(speech_fpath)\n",
    "print(len(speech_file_entries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "noise_fpath = \"noise/noise/\"\n",
    "noise_file_entries = os.listdir(noise_fpath)\n",
    "print(len(noise_file_entries))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3) Normalise and downsample speech from 48K to 16K and normalise noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_lowpass(cutoff, fs, order=5):\n",
    "    return butter(order, cutoff, fs=fs, btype='low', analog=False)\n",
    "\n",
    "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
    "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsampling(clip):\n",
    "    samplerate, data = wavfile.read(clip)\n",
    "    Fs1 = samplerate\n",
    "    Fs2 = 16000\n",
    "    N = len(data)\n",
    "    total_time = (N-1)/Fs1\n",
    "    Max_Signal_Frequency =Fs2/2\n",
    "    New_sample_amount = math.ceil(Fs2*total_time)\n",
    "    Single_Channel = np.zeros(New_sample_amount)\n",
    "    Bit_Check = wave.open(clip)\n",
    "    bit_depth = Bit_Check.getsampwidth() * 8\n",
    "    data = data/(2**(bit_depth-1))\n",
    "    Original_signal = data\n",
    "    Anti_Aliased_signal = np.array(butter_lowpass_filter(Original_signal,Max_Signal_Frequency,Fs1))\n",
    "    Down_sampled_signal = np.array(sps.resample(Anti_Aliased_signal,New_sample_amount))\n",
    "    Single_Channel = Down_sampled_signal\n",
    "    Transformed_single_channel = Single_Channel.transpose()\n",
    "    return Transformed_single_channel, Fs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(inclip, outclip):\n",
    "    rawsound = AudioSegment.from_wav(inclip)  \n",
    "    normalizedsound = effects.normalize(rawsound)  \n",
    "    normalizedsound.export(outclip, format = 'wav')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4) Adding noise to speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adding_noise_to_speech(speech, noise, i):\n",
    "    speech, _ = torchaudio.load(speech)\n",
    "    noise, _ = torchaudio.load(noise)\n",
    "\n",
    "    # From a random point in the noise waveform make the size of the noise the same as the speech\n",
    "    first = random.randint(0, noise.shape[1] - speech.shape[1])\n",
    "    noise = noise[:, first:first + speech.shape[1]]\n",
    "\n",
    "    # Calculate the time range of the noise in minutes\n",
    "    noise_start_time = first / 16000\n",
    "    # At all SNR levels add the noise to the speech\n",
    "    snr_dbs = torch.tensor([0, -3, -6, -9, 3, 6, 9], device=device)\n",
    "    noisy_speeches = F.add_noise(speech.to(device), noise.to(device), snr_dbs)\n",
    "\n",
    "    snr_db, noisy_speech = snr_dbs[0].item(), noisy_speeches[0:1]\n",
    "    torchaudio.save(path_0dB + \"speech_\" + str(i) + \".wav\", noisy_speech.cpu(), 16000, encoding=\"PCM_S\", bits_per_sample=16)\n",
    "\n",
    "    snr_db, noisy_speech = snr_dbs[1].item(), noisy_speeches[1:2]\n",
    "    torchaudio.save(path_n3dB + \"speech_\" + str(i) + \".wav\", noisy_speech.cpu(), 16000, encoding=\"PCM_S\", bits_per_sample=16)\n",
    "\n",
    "    snr_db, noisy_speech = snr_dbs[2].item(), noisy_speeches[2:3]\n",
    "    torchaudio.save(path_n6dB + \"speech_\" + str(i) + \".wav\", noisy_speech.cpu(), 16000, encoding=\"PCM_S\", bits_per_sample=16)\n",
    "\n",
    "    snr_db, noisy_speech = snr_dbs[3].item(), noisy_speeches[3:4]\n",
    "    torchaudio.save(path_n9dB + \"speech_\" + str(i) + \".wav\", noisy_speech.cpu(), 16000, encoding=\"PCM_S\", bits_per_sample=16)\n",
    "\n",
    "    snr_db, noisy_speech = snr_dbs[4].item(), noisy_speeches[4:5]\n",
    "    torchaudio.save(path_3dB + \"speech_\" + str(i)+ \".wav\", noisy_speech.cpu(), 16000, encoding=\"PCM_S\", bits_per_sample=16)\n",
    "\n",
    "    snr_db, noisy_speech = snr_dbs[5].item(), noisy_speeches[5:6]\n",
    "    torchaudio.save(path_6dB + \"speech_\" + str(i) + \".wav\", noisy_speech.cpu(), 16000, encoding=\"PCM_S\", bits_per_sample=16)\n",
    "\n",
    "    snr_db, noisy_speech = snr_dbs[6].item(), noisy_speeches[6:7]\n",
    "    torchaudio.save(path_9dB + \"speech_\" + str(i) + \".wav\", noisy_speech.cpu(), 16000, encoding=\"PCM_S\", bits_per_sample=16)\n",
    "\n",
    "    # Save the noisy speech at different SNR levels\n",
    "    for j, snr_db in enumerate(snr_dbs):\n",
    "        snr_db = snr_db.item()\n",
    "        noisy_speech = noisy_speeches[j:j+1]\n",
    "        # Save the noise separately at each SNR level\n",
    "        noise_at_snr = noisy_speech - speech.to(device)\n",
    "        torchaudio.save(path_noise + \"/\" + str(snr_db) + \"dB/noise_\" + str(i) + \".wav\", noise_at_snr.cpu(), 16000, encoding=\"PCM_S\", bits_per_sample=16)\n",
    "        \n",
    "    return noise_start_time\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5) Create all and classification data with excel information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 10 noisy file: PCAFETER_16k clean file: p228 duration: 5.16 seconds\r"
     ]
    }
   ],
   "source": [
    "n = 10\n",
    "\n",
    "for i in range (0, n):\n",
    "\n",
    "    #Selecting the clean speech\n",
    "\n",
    "    # Random number to select the clean speech file (speaker) used\n",
    "    ran_1 = random.randrange(0, len(speech_file_entries) - 2) # ignoring the last file used for testing\n",
    "    speech_file = speech_file_entries[ran_1]\n",
    "    speech_enter = speech_fpath + speech_file + \"/\"\n",
    "    speech_entries = os.listdir(speech_enter)\n",
    "\n",
    "    # Random number to select the passage used\n",
    "    ran_2 = random.randrange(0, len(speech_entries) - 1)\n",
    "    select_speech = speech_enter + speech_entries[ran_2]\n",
    "\n",
    "    # Selecting the noise\n",
    "    ran_3 = random.randrange(0, len(noise_file_entries) - 2)\n",
    "    noise_file = noise_file_entries[ran_3]\n",
    "    noise_enter = noise_fpath + noise_file + \"/\" + noise_file.split(\"_\")[0] + \"/\"\n",
    "    noise_entries = os.listdir(noise_enter)\n",
    "\n",
    "    # Random number to select the channel used\n",
    "    ran_4 = random.randrange(0, len(noise_entries) - 1)\n",
    "    select_noise = noise_enter + noise_entries[ran_4]\n",
    "\n",
    "    # downsampling then normalising the clean speech\n",
    "    data, samplerate = downsampling(select_speech)\n",
    "    sf.write(path_clean + \"speech_\" + str(i + 1) + \".wav\", data, samplerate, 'PCM_16')\n",
    "    normalise(path_clean + \"speech_\" + str(i + 1) + \".wav\", path_clean + \"speech_\" + str(i + 1) + \".wav\")\n",
    "    \n",
    "    # normalising the noisy speech\n",
    "    normalise(select_noise, path_noisy + \"noisy_\" + str(i + 1) + \".wav\")\n",
    "\n",
    "    # Combinding the clean speech and the noise\n",
    "    noise_start_time = adding_noise_to_speech(path_clean + \"speech_\" + str(i + 1) + \".wav\", path_noisy + \"noisy_\" + str(i + 1) + \".wav\", i + 1)\n",
    "\n",
    "    # Adding the information to the excel file (path3/wf2 is classification, path4/wf1 is all)\n",
    "    duration = round(librosa.get_duration(path=select_speech), 2) # Duration of speech\n",
    "    passage_ID = speech_entries[ran_2].split('.')[0].split('_')[1] # Passage ID\n",
    "    noise_channel = noise_entries[ran_4].split('.')[0]# Noise channel\n",
    "\n",
    "    workfile1 = openpyxl.load_workbook(path3)\n",
    "\n",
    "    sheet1 = workfile1.active\n",
    "\n",
    "    sheet1.cell(row=i+2, column=1).value = i+1\n",
    "    sheet1.cell(row=i+2, column=2).value = \"speech_\" + str(i + 1) + \".wav\"\n",
    "    sheet1.cell(row=i+2, column=3).value = duration\n",
    "    sheet1.cell(row=i+2, column=4).value = \"noisy | clean\"\n",
    "    sheet1.cell(row=i+2, column=5).value = \"0 | -3 | -6 | -9 | 3 | 6 | 9\"\n",
    "    sheet1.cell(row=i+2, column=6).value = noise_file\n",
    "    sheet1.cell(row=i+2, column=7).value = noise_channel\n",
    "    sheet1.cell(row=i+2, column=8).value = speech_file\n",
    "    sheet1.cell(row=i+2, column=9).value = passage_ID\n",
    "    sheet1.cell(row=i+2, column=10).value = noise_start_time\n",
    "\n",
    "    workfile1.save(path3)\n",
    "\n",
    "    print(\"iteration: \" + str(i + 1) + \" noisy file: \" + noise_file + \" clean file: \" + speech_file + \" duration: \" + str(duration) + \" seconds\", end = \"\\r\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
