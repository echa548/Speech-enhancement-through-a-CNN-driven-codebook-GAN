{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Edward\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1+cu117\n",
      "2.0.2+cu117\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.functional as F\n",
    "import torchaudio.transforms as transforms\n",
    "\n",
    "import math\n",
    "\n",
    "from IPython.display import Audio\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import os\n",
    "from torchaudio.utils import download_asset\n",
    "\n",
    "from scipy.io import wavfile\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from pathlib import Path\n",
    "import scipy.signal as sps\n",
    "from scipy.signal import butter, lfilter\n",
    "import random\n",
    "import pydub\n",
    "import uuid\n",
    "from pydub import AudioSegment, effects\n",
    "import soundfile as sf\n",
    "import shutil\n",
    "import openpyxl\n",
    "\n",
    "import xlsxwriter\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchaudio.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1) Creating files for all data and classifications with its respective excel page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All locations\n",
    "path_clean = \"dataset_all/clean/\"\n",
    "path_noisy = \"dataset_all/noisy/\"\n",
    "path_noisy_3dB = \"dataset_all/-3dB/\"\n",
    "path_noisy_6dB = \"dataset_all/-6dB/\"\n",
    "path_noisy_9dB = \"dataset_all/-9dB/\"\n",
    "path = \"dataset_all\"\n",
    "path2 = \"dataset_classification\"\n",
    "path3 = path + \"/all_info.xlsx\"\n",
    "path4 = path2 + \"/classification_info.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xlsxwriter\n",
    "\n",
    "isExist = os.path.exists(path)\n",
    "if not isExist:\n",
    "   # Create a new directory because it does not exist\n",
    "   os.makedirs(path)\n",
    "   os.makedirs(path + \"/clean\")\n",
    "   os.makedirs(path + \"/noisy\")\n",
    "   os.makedirs(path + \"/-3dB\")\n",
    "   os.makedirs(path + \"/-6dB\")\n",
    "   os.makedirs(path + \"/-9dB\")\n",
    "   print(\"the %s directory is created!\", path)\n",
    "\n",
    "isExist2 = os.path.exists(path2)\n",
    "if not isExist2:\n",
    "   # Create a new directory because it does not exist\n",
    "   os.makedirs(path2)\n",
    "   os.makedirs(path2 + \"/clean\")\n",
    "   os.makedirs(path2 + \"/noisy\")\n",
    "   print(\"The %s directory is created!\", path2)\n",
    "\n",
    "isExist3 = os.path.exists(path3)\n",
    "if not isExist3:\n",
    "   workbook1 = xlsxwriter.Workbook(path3)\n",
    "   worksheet1 = workbook1.add_worksheet()\n",
    "   worksheet1.write(0, 0, \"Sample Number\")\n",
    "   worksheet1.write(0, 1, \"Name\")\n",
    "   worksheet1.write(0, 2, \"Length(s)\")\n",
    "   worksheet1.write(0, 3, \"Type of Speech\")\n",
    "   worksheet1.write(0, 4, \"SNR(dB)\")\n",
    "   worksheet1.write(0, 5, \"Noise Type\")\n",
    "   worksheet1.write(0, 6, \"Noise Channel\")\n",
    "   worksheet1.write(0, 7, \"Speaker ID\")\n",
    "   worksheet1.write(0, 8, \"Passage ID\")\n",
    "   print(\"The excel file 1 is created!\")\n",
    "   workbook1.close()\n",
    "\n",
    "isExist4 = os.path.exists(path4)\n",
    "if not isExist4:\n",
    "   workbook2 = xlsxwriter.Workbook(path4)\n",
    "   worksheet2 = workbook2.add_worksheet()\n",
    "   worksheet2.write(0, 0, \"Sample Number\")\n",
    "   worksheet2.write(0, 1, \"Name\")\n",
    "   worksheet2.write(0, 2, \"Length(s)\")\n",
    "   worksheet2.write(0, 3, \"Type of Speech\")\n",
    "   worksheet2.write(0, 4, \"SNR(dB)\")\n",
    "   worksheet2.write(0, 5, \"Noise Type\")\n",
    "   worksheet2.write(0, 6, \"Noise Channel\")\n",
    "   worksheet2.write(0, 7, \"Speaker ID\")\n",
    "   worksheet2.write(0, 8, \"Passage ID\")\n",
    "   print(\"The excel file 2 is created!\")\n",
    "   workbook2.close()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2) Locations of speech and noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109\n"
     ]
    }
   ],
   "source": [
    "speech_fpath = \"speech/VCTK-Corpus/wav48/\"\n",
    "speech_file_entries = os.listdir(speech_fpath)\n",
    "print(len(speech_file_entries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "noise_fpath = \"noise/noise/\"\n",
    "noise_file_entries = os.listdir(noise_fpath)\n",
    "print(len(noise_file_entries))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3) Normalise and downsample speech from 48K to 16K and normalise noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_lowpass(cutoff, fs, order=5):\n",
    "    return butter(order, cutoff, fs=fs, btype='low', analog=False)\n",
    "\n",
    "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
    "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsampling(clip):\n",
    "    samplerate, data = wavfile.read(clip)\n",
    "    Fs1 = samplerate\n",
    "    Fs2 = 16000\n",
    "    N = len(data)\n",
    "    total_time = (N-1)/Fs1\n",
    "    Max_Signal_Frequency =Fs2/2\n",
    "    New_sample_amount = math.ceil(Fs2*total_time)\n",
    "    Single_Channel = np.zeros(New_sample_amount)\n",
    "    bit_depth = data.getsampwidth() * 8\n",
    "    data = data/(2**(bit_depth-1))\n",
    "    Original_signal = data\n",
    "    Anti_Aliased_signal = np.array(butter_lowpass_filter(Original_signal,Max_Signal_Frequency,Fs1))\n",
    "    Down_sampled_signal = np.array(sps.resample(Anti_Aliased_signal,New_sample_amount))\n",
    "    Single_Channel = Down_sampled_signal\n",
    "    Transformed_single_channel = Single_Channel.transpose()\n",
    "    return Transformed_single_channel, Fs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(inclip, outclip):\n",
    "    rawsound = AudioSegment.from_wav(inclip)  \n",
    "    normalizedsound = effects.normalize(rawsound)  \n",
    "    normalizedsound.export(outclip, format = 'wav')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4) Adding noise to speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adding_noise_to_speech(speech, noise, i):\n",
    "    speech, _ = torchaudio.load(speech)\n",
    "    noise, _ = torchaudio.load(noise)\n",
    "\n",
    "    # From a random point in the noise waveform make the size of the noise the same as the speech\n",
    "    first = random.randint(0, noise.shape[1] - speech.shape[1])\n",
    "    noise = noise[:, first:first + speech.shape[1]]\n",
    "\n",
    "    # At all SNR levels add the noise to the speech\n",
    "    snr_dbs = torch.tensor([-3, -6, -9])\n",
    "    noisy_speeches = F.add_noise(speech, noise, snr_dbs)\n",
    "\n",
    "    snr_db, noisy_speech = snr_dbs[0], noisy_speeches[0:1]\n",
    "    torchaudio.save(path_noisy_3dB + \"speech_\" + str(i) + \".wav\", noisy_speech, 16000, encoding=\"PCM_S\", bits_per_sample=16)\n",
    "\n",
    "    snr_db, noisy_speech = snr_dbs[1], noisy_speeches[1:2]\n",
    "    torchaudio.save(path_noisy_6dB + \"speech_\" + str(i) + \".wav\", noisy_speech, 16000, encoding=\"PCM_S\", bits_per_sample=16)\n",
    "\n",
    "    snr_db, noisy_speech = snr_dbs[2], noisy_speeches[2:3]\n",
    "    torchaudio.save(path_noisy_9dB + \"speech_\" + str(i) + \".wav\", noisy_speech, 16000, encoding=\"PCM_S\", bits_per_sample=16)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5) Create all and classification data with excel information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 10000 noisy file: OOFFICE_16k clean file: p317 SNR: -3 duration: 2.9 seconds:   \r"
     ]
    }
   ],
   "source": [
    "n = 10000\n",
    "\n",
    "for i in range (0, n):\n",
    "\n",
    "    #Selecting the clean speech\n",
    "\n",
    "    # Random number to select the clean speech file (speaker) used\n",
    "    ran_1 = random.randrange(0, len(speech_file_entries) - 2) # ignoring the last file used for testing\n",
    "    speech_file = speech_file_entries[ran_1]\n",
    "    speech_enter = speech_fpath + speech_file + \"/\"\n",
    "    speech_entries = os.listdir(speech_enter)\n",
    "\n",
    "    # Random number to select the passage used\n",
    "    ran_2 = random.randrange(0, len(speech_entries) - 1)\n",
    "    select_speech = speech_enter + speech_entries[ran_2]\n",
    "\n",
    "    # Selecting the noise\n",
    "    ran_3 = random.randrange(0, len(noise_file_entries) - 2)\n",
    "    noise_file = noise_file_entries[ran_3]\n",
    "    noise_enter = noise_fpath + noise_file + \"/\" + noise_file.split(\"_\")[0] + \"/\"\n",
    "    noise_entries = os.listdir(noise_enter)\n",
    "\n",
    "    # Random number to select the channel used\n",
    "    ran_4 = random.randrange(0, len(noise_entries) - 1)\n",
    "    select_noise = noise_enter + noise_entries[ran_4]\n",
    "\n",
    "    # downsampling then normalising the clean speech\n",
    "    data, samplerate = downsampling(select_speech)\n",
    "    sf.write(path_clean + \"speech_\" + str(i + 1) + \".wav\", data, samplerate, 'PCM_16')\n",
    "    normalise(path_clean + \"speech_\" + str(i + 1) + \".wav\", path_clean + \"speech_\" + str(i + 1) + \".wav\")\n",
    "    \n",
    "    # normalising the noisy speech\n",
    "    normalise(select_noise, path_noisy + \"noisy_\" + str(i + 1) + \".wav\")\n",
    "\n",
    "    # Combinding the clean speech and the noise\n",
    "    adding_noise_to_speech(path_clean + \"speech_\" + str(i + 1) + \".wav\", path_noisy + \"noisy_\" + str(i + 1) + \".wav\", i + 1)\n",
    "\n",
    "    # Selecting the noisy speech for classification\n",
    "    ran_5 = random.randint(1, 4)\n",
    "    if ran_5 == 1:\n",
    "        shutil.copy(path_clean + \"speech_\" + str(i + 1) + \".wav\", path2 + \"/clean\")\n",
    "        SNR = 0\n",
    "        type_of_speech = \"clean\"\n",
    "    elif ran_5 == 2:\n",
    "        shutil.copy(path_noisy_3dB + \"speech_\" + str(i + 1) + \".wav\", path2 + \"/noisy\")\n",
    "        SNR = -3\n",
    "        type_of_speech = \"noisy\"\n",
    "    elif ran_5 == 3:\n",
    "        shutil.copy(path_noisy_6dB + \"speech_\" + str(i + 1) + \".wav\", path2 + \"/noisy\")\n",
    "        SNR = -6\n",
    "        type_of_speech = \"noisy\"\n",
    "    else:\n",
    "        shutil.copy(path_noisy_9dB + \"speech_\" + str(i + 1) + \".wav\", path2 + \"/noisy\")\n",
    "        SNR = -9\n",
    "        type_of_speech = \"noisy\"\n",
    "\n",
    "\n",
    "    # Adding the information to the excel file (path3/wf2 is classification, path4/wf1 is all)\n",
    "    duration = round(librosa.get_duration(path=select_speech), 2) # Duration of speech\n",
    "    passage_ID = speech_entries[ran_2].split('.')[0].split('_')[1] # Passage ID\n",
    "    noise_channel = noise_entries[ran_4].split('.')[0]# Noise channel\n",
    "\n",
    "    workfile1 = openpyxl.load_workbook(path3)\n",
    "    workfile2 = openpyxl.load_workbook(path4)\n",
    "\n",
    "    sheet1 = workfile1.active\n",
    "    sheet2 = workfile2.active\n",
    "\n",
    "    sheet1.cell(row=i+2, column=1).value = i+1\n",
    "    sheet1.cell(row=i+2, column=2).value = \"speech_\" + str(i + 1) + \".wav\"\n",
    "    sheet1.cell(row=i+2, column=3).value = duration\n",
    "    sheet1.cell(row=i+2, column=4).value = \"noisy | clean\"\n",
    "    sheet1.cell(row=i+2, column=5).value = \"0 | -3 | -6 | -9\"\n",
    "    sheet1.cell(row=i+2, column=6).value = noise_file\n",
    "    sheet1.cell(row=i+2, column=7).value = noise_channel\n",
    "    sheet1.cell(row=i+2, column=8).value = speech_file\n",
    "    sheet1.cell(row=i+2, column=9).value = passage_ID\n",
    "\n",
    "    sheet2.cell(row=i+2, column=1).value = i+1\n",
    "    sheet2.cell(row=i+2, column=2).value = \"speech_\" + str(i + 1) + \".wav\"\n",
    "    sheet2.cell(row=i+2, column=3).value = duration\n",
    "    sheet2.cell(row=i+2, column=4).value = type_of_speech\n",
    "    sheet2.cell(row=i+2, column=5).value = SNR\n",
    "    sheet2.cell(row=i+2, column=6).value = noise_file\n",
    "    sheet2.cell(row=i+2, column=7).value = noise_channel\n",
    "    sheet2.cell(row=i+2, column=8).value = speech_file\n",
    "    sheet2.cell(row=i+2, column=9).value = passage_ID\n",
    "\n",
    "    workfile1.save(path3)\n",
    "    workfile2.save(path4)\n",
    "\n",
    "    print(\"iteration: \" + str(i + 1) + \" noisy file: \" + noise_file + \" clean file: \" + speech_file + \" SNR: \" + str(SNR) + \" duration: \" + str(duration) + \" seconds\", end = \"\\r\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
