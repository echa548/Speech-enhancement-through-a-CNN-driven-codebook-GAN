{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1+cu117\n",
      "2.0.2+cu117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Edward\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.functional as F\n",
    "import torchaudio.transforms as transforms\n",
    "\n",
    "import math\n",
    "\n",
    "from IPython.display import Audio\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torchaudio.utils import download_asset\n",
    "\n",
    "from scipy.io import wavfile\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from pathlib import Path\n",
    "import scipy.signal as sps\n",
    "from scipy.signal import butter, lfilter\n",
    "import soundfile as sf\n",
    "import pydub\n",
    "import uuid\n",
    "from pydub import AudioSegment, effects\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchaudio.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_waveform(waveform, sample_rate, title=\"Waveform\", xlim=None):\n",
    "    waveform = waveform.numpy()\n",
    "\n",
    "    num_channels, num_frames = waveform.shape\n",
    "    time_axis = torch.arange(0, num_frames) / sample_rate\n",
    "\n",
    "    figure, axes = plt.subplots(num_channels, 1)\n",
    "    if num_channels == 1:\n",
    "        axes = [axes]\n",
    "    for c in range(num_channels):\n",
    "        axes[c].plot(time_axis, waveform[c], linewidth=1)\n",
    "        axes[c].grid(True)\n",
    "        if num_channels > 1:\n",
    "            axes[c].set_ylabel(f\"Channel {c+1}\")\n",
    "        if xlim:\n",
    "            axes[c].set_xlim(xlim)\n",
    "    figure.suptitle(title)\n",
    "    plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_specgram(waveform, sample_rate, title=\"Spectrogram\", xlim=None):\n",
    "    waveform = waveform.numpy()\n",
    "\n",
    "    num_channels, _ = waveform.shape\n",
    "\n",
    "    figure, axes = plt.subplots(num_channels, 1)\n",
    "    if num_channels == 1:\n",
    "        axes = [axes]\n",
    "    for c in range(num_channels):\n",
    "        axes[c].specgram(waveform[c], Fs=sample_rate)\n",
    "        if num_channels > 1:\n",
    "            axes[c].set_ylabel(f\"Channel {c+1}\")\n",
    "        if xlim:\n",
    "            axes[c].set_xlim(xlim)\n",
    "    figure.suptitle(title)\n",
    "    plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of .wav files in speech folder =  10\n",
      "No. of .wav files in noise folder =  10\n"
     ]
    }
   ],
   "source": [
    "speech_fpath = \"sample_audio/speech/\"\n",
    "speech_clips = os.listdir(speech_fpath)\n",
    "noise_fpath = \"sample_audio/noise/\"\n",
    "noise_clips = os.listdir(noise_fpath)\n",
    "print(\"No. of .wav files in speech folder = \",len(speech_clips))\n",
    "print(\"No. of .wav files in noise folder = \",len(noise_clips))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 3, 6, 7, 1, 8, 9, 2, 5]\n"
     ]
    }
   ],
   "source": [
    "#Randomise speech files can not be used twice\n",
    "import random\n",
    "speech_ran_list = random.sample(range(len(speech_clips)), len(speech_clips))\n",
    "print(speech_ran_list)\n",
    "\n",
    "for i in range(0, len(speech_clips)):\n",
    "    os.rename(speech_fpath + speech_clips[i], speech_fpath + str(speech_ran_list[i]) + \"_speech.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_lowpass(cutoff, fs, order=5):\n",
    "    return butter(order, cutoff, fs=fs, btype='low', analog=False)\n",
    "\n",
    "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
    "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of .wav files in test speech folder =  0\n",
      "No. of .wav files in test noise folder =  0\n"
     ]
    }
   ],
   "source": [
    "test_speech_fpath = \"sample_audio/test_speech/\"\n",
    "test_speech_clips = os.listdir(test_speech_fpath)\n",
    "test_noise_fpath = \"sample_audio/test_noise/\"\n",
    "test_noise_clips = os.listdir(test_noise_fpath)\n",
    "print(\"No. of .wav files in test speech folder = \",len(test_speech_clips))\n",
    "print(\"No. of .wav files in test noise folder = \",len(test_noise_clips))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of .wav files in speech folder =  10\n",
      "No. of .wav files in noise folder =  10\n"
     ]
    }
   ],
   "source": [
    "speech_fpath = \"sample_audio/speech/\"\n",
    "speech_clips = os.listdir(speech_fpath)\n",
    "noise_fpath = \"sample_audio/noise/\"\n",
    "noise_clips = os.listdir(noise_fpath)\n",
    "print(\"No. of .wav files in speech folder = \",len(speech_clips))\n",
    "print(\"No. of .wav files in noise folder = \",len(noise_clips))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0, len(speech_clips)):\n",
    "   samplerate, data = wavfile.read(speech_fpath + speech_clips[i])\n",
    "   Fs1 = samplerate\n",
    "   Fs2 = 16000\n",
    "   N = len(data)\n",
    "   total_time = (N-1)/Fs1\n",
    "   Max_Signal_Frequency =Fs2/2\n",
    "   New_sample_amount = math.ceil(Fs2*total_time)\n",
    "   Single_Channel = np.zeros(New_sample_amount)\n",
    "   data = data/(2**(15-1))\n",
    "   Original_signal = data\n",
    "   Anti_Aliased_signal = np.array(butter_lowpass_filter(Original_signal,Max_Signal_Frequency,Fs1))\n",
    "   Down_sampled_signal = np.array(sps.resample(Anti_Aliased_signal,New_sample_amount))\n",
    "   Single_Channel = Down_sampled_signal\n",
    "   Transformed_single_channel = Single_Channel.transpose()\n",
    "   sf.write(test_speech_fpath + \"speech_\" + str(i) +\".wav\", Transformed_single_channel, Fs2, 'PCM_16')\n",
    "   rawsound = AudioSegment.from_wav(test_speech_fpath + \"speech_\" + str(i) +\".wav\")  \n",
    "   normalizedsound = effects.normalize(rawsound)  \n",
    "   normalizedsound.export(test_speech_fpath + \"speech_\" + str(i) +\".wav\", format = 'wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0, len(noise_clips)):\n",
    "   rawsound = AudioSegment.from_wav(noise_fpath + noise_clips[i])  \n",
    "   normalizedsound = effects.normalize(rawsound)  \n",
    "   normalizedsound.export(test_noise_fpath + \"noise_norm\" + str(i) +\".wav\", format = 'wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of .wav files in speech folder =  10\n",
      "No. of .wav files in noise folder =  10\n",
      "No. of .wav files in test speech folder =  10\n",
      "No. of .wav files in test noise folder =  10\n"
     ]
    }
   ],
   "source": [
    "test_speech_fpath = \"sample_audio/test_speech/\"\n",
    "test_speech_clips = os.listdir(test_speech_fpath)\n",
    "test_noise_fpath = \"sample_audio/test_noise/\"\n",
    "test_noise_clips = os.listdir(test_noise_fpath)\n",
    "speech_fpath = \"sample_audio/speech/\"\n",
    "speech_clips = os.listdir(speech_fpath)\n",
    "noise_fpath = \"sample_audio/noise/\"\n",
    "noise_clips = os.listdir(noise_fpath)\n",
    "print(\"No. of .wav files in speech folder = \",len(speech_clips))\n",
    "print(\"No. of .wav files in noise folder = \",len(noise_clips))\n",
    "print(\"No. of .wav files in test speech folder = \",len(test_speech_clips))\n",
    "print(\"No. of .wav files in test noise folder = \",len(test_noise_clips))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 4, 1, 2, 0, 8, 9, 3, 7, 5]\n"
     ]
    }
   ],
   "source": [
    "#Randomise noise files can one be done once\n",
    "import random\n",
    "noise_ran_list = random.sample(range(len(test_noise_clips)), len(test_noise_clips))\n",
    "print(noise_ran_list)\n",
    "\n",
    "for i in range(0, len(test_noise_clips)):\n",
    "    os.rename(test_noise_fpath + test_noise_clips[i], test_noise_fpath + str(noise_ran_list[i]) + \"_noise.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of .wav files in speech folder =  10\n",
      "No. of .wav files in noise folder =  10\n",
      "No. of .wav files in test speech folder =  10\n",
      "No. of .wav files in test noise folder =  10\n"
     ]
    }
   ],
   "source": [
    "test_speech_fpath = \"sample_audio/test_speech/\"\n",
    "test_speech_clips = os.listdir(test_speech_fpath)\n",
    "test_noise_fpath = \"sample_audio/test_noise/\"\n",
    "test_noise_clips = os.listdir(test_noise_fpath)\n",
    "speech_fpath = \"sample_audio/speech/\"\n",
    "speech_clips = os.listdir(speech_fpath)\n",
    "noise_fpath = \"sample_audio/noise/\"\n",
    "noise_clips = os.listdir(noise_fpath)\n",
    "print(\"No. of .wav files in speech folder = \",len(speech_clips))\n",
    "print(\"No. of .wav files in noise folder = \",len(noise_clips))\n",
    "print(\"No. of .wav files in test speech folder = \",len(test_speech_clips))\n",
    "print(\"No. of .wav files in test noise folder = \",len(test_noise_clips))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding all noise and speech together at different SNR levels\n",
    "\n",
    "for i in range(0, len(speech_clips)):\n",
    "  #waveform1, sample_rate1 = torchaudio.load(test_speech_fpath + test_speech_clips[i])\n",
    "  #waveform2, sample_rate2 = torchaudio.load(test_noise_fpath + test_noise_clips[i])\n",
    "\n",
    "  # Load waveforms\n",
    "  speech, _ = torchaudio.load(test_speech_fpath + test_speech_clips[i])\n",
    "  noise, _ = torchaudio.load(test_noise_fpath + test_noise_clips[i])\n",
    "\n",
    "  # From a random point in the noise waveform make the size of the noise the same as the speech\n",
    "  first = random.randint(0, noise.shape[1] - speech.shape[1])\n",
    "  noise = noise[:, first:first + speech.shape[1]]\n",
    "\n",
    "  # At all SNR levels add the noise to the speech\n",
    "  snr_dbs = torch.tensor([-3, -6, -9])\n",
    "  noisy_speeches = F.add_noise(speech, noise, snr_dbs)\n",
    "\n",
    "  snr_db, noisy_speech = snr_dbs[0], noisy_speeches[0:1]\n",
    "  torchaudio.save(\"sample_audio/noisy_speech/SNR_-3dB/\" + \"SNR_-3dB_\" + str(i) + \".wav\", noisy_speech, 16000, encoding=\"PCM_S\", bits_per_sample=16)\n",
    "\n",
    "  snr_db, noisy_speech = snr_dbs[1], noisy_speeches[1:2]\n",
    "  torchaudio.save(\"sample_audio/noisy_speech/SNR_-6dB/\" + \"SNR_-6dB_\" + str(i) + \".wav\", noisy_speech, 16000, encoding=\"PCM_S\", bits_per_sample=16)\n",
    "\n",
    "  snr_db, noisy_speech = snr_dbs[2], noisy_speeches[2:3]\n",
    "  torchaudio.save(\"sample_audio/noisy_speech/SNR_-9dB/\" + \"SNR_-9dB_\" + str(i) + \".wav\", noisy_speech, 16000, encoding=\"PCM_S\", bits_per_sample=16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
