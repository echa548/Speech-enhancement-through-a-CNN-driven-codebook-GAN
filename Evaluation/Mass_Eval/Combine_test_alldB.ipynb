{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1+cpu\n",
      "2.0.2+cpu\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import scipy.signal as sps\n",
    "import soundfile as sf\n",
    "import os\n",
    "import math\n",
    "import wave\n",
    "from scipy.io import wavfile\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "import xlsxwriter\n",
    "import openpyxl\n",
    "import random\n",
    "\n",
    "from pesq import pesq, NoUtterancesError\n",
    "from pystoi import stoi\n",
    "import mir_eval\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "from torchaudio.utils import download_asset\n",
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.functional as F\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchaudio.__version__)\n",
    "\n",
    "%matplotlib inline\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "if physical_devices:\n",
    "  tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spectrogram(audio_file, image_file):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1)\n",
    "\n",
    "    y, sr = librosa.load(audio_file)\n",
    "    ms = librosa.feature.melspectrogram(y=y, sr=sr, S=None, n_fft=1024, hop_length=80, win_length=320, window='hann', center=True, pad_mode='constant', power=2.0)\n",
    "    #ms = librosa.feature.melspectrogram(y=y, sr=sr, S=None)\n",
    "    log_ms = librosa.power_to_db(ms, ref=np.max)\n",
    "    librosa.display.specshow(log_ms, sr=sr)\n",
    "\n",
    "    fig.savefig(image_file)\n",
    "    plt.close(fig)\n",
    "    \n",
    "def create_pngs_from_wavs(input_path, output_path):\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "\n",
    "    dir = os.listdir(input_path)\n",
    "\n",
    "    for i, file in enumerate(dir):\n",
    "        input_file = os.path.join(input_path, file)\n",
    "        output_file = os.path.join(output_path, file.replace('.wav', '.png'))\n",
    "        create_spectrogram(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_path(path, label, limit=1500):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    file_list = os.listdir(path)\n",
    "    if limit is not None:\n",
    "        file_list = file_list[:limit]\n",
    "\n",
    "    for file in file_list:\n",
    "        images.append(img_to_array(load_img(os.path.join(path, file), target_size=(224, 224, 3))))\n",
    "        labels.append(label)\n",
    "        \n",
    "    return images, labels\n",
    "\n",
    "def show_images(images):\n",
    "    fig, axes = plt.subplots(1, 8, figsize=(20, 20), subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        ax.imshow(images[i] / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 111, 111, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 109, 109, 128)     36992     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 54, 54, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 52, 52, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 26, 26, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 24, 24, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 12, 12, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 18432)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              18875392  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 8200      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,216,648\n",
      "Trainable params: 19,216,648\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Recreate the exact same model, including its weights and the optimizer\n",
    "new_model = tf.keras.models.load_model('models/my_model.h5')\n",
    "\n",
    "# Show the model architecture\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the %s directory is created! Spectrograms_wide_VA/ForTim/\n"
     ]
    }
   ],
   "source": [
    "path = \"Spectrograms_wide_VA\"\n",
    "\n",
    "path_spec_test = path + \"/ForTim/\"\n",
    "\n",
    "isExist = os.path.exists(path_spec_test)\n",
    "if not isExist:\n",
    "    # Create a new directory because it does not exist\n",
    "    os.makedirs(path_spec_test)\n",
    "    print(\"the %s directory is created!\", path_spec_test)\n",
    "\n",
    "noisy = [\"-3dB\", \"-6dB\", \"-9dB\", \"0dB\"]\n",
    "clean = [\"3dB\", \"6dB\", \"9dB\", \"clean\"]\n",
    "target_names = [\"clean\", \"0dB\", \"-3dB\", \"-6dB\", \"-9dB\", \"3dB\", \"6dB\", \"9dB\"]\n",
    "user_target = [\"0dB\", \"-3dB\", \"-6dB\", \"-9dB\", \"3dB\", \"6dB\", \"9dB\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_path = path_spec_test + \"/combine.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The excel file 1 is created!\n"
     ]
    }
   ],
   "source": [
    "isExist3 = os.path.exists(ex_path)\n",
    "if not isExist3:\n",
    "   workbook1 = xlsxwriter.Workbook(ex_path)\n",
    "   worksheet1 = workbook1.add_worksheet()\n",
    "   worksheet1.write(0, 0, \"Number\")\n",
    "   worksheet1.write(0, 1, \"Name\")\n",
    "   worksheet1.write(0, 2, \"Original SNR(dB)\")\n",
    "   worksheet1.write(0, 3, \"Alpha Value\")\n",
    "   worksheet1.write(0, 4, \"SNR(dB)\")\n",
    "   worksheet1.write(0, 5, \"PESQ Evaluation\")\n",
    "   worksheet1.write(0, 6, \"STOI Evaluation\")\n",
    "   worksheet1.write(0, 7, \"SDR Evaluation\")\n",
    "   worksheet1.write(0, 8, \"SI-SDR Evaluation\")\n",
    "   worksheet1.write(0, 9, \"PESQ Highest\")\n",
    "   worksheet1.write(0, 10, \"STOI Highest\")\n",
    "   print(\"The excel file 1 is created!\")\n",
    "   workbook1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hann_window_a_signal(Windowed_data):\n",
    "    Hann_window = sps.windows.hann(len(Windowed_data))\n",
    "    Hann_Windowed_data = Hann_window * Windowed_data\n",
    "    padded_signal = np.pad(Hann_Windowed_data, (0, 512), 'constant')\n",
    "    Windowed_data_fft = np.fft.fft(padded_signal, 1024)\n",
    "    return Windowed_data_fft\n",
    "\n",
    "def perform_gan_noise_subtraction(input_audio_file, output_audio_file, alpha, Noise_gan):\n",
    "    N_fft = 1024\n",
    "\n",
    "    samplerate, data = wavfile.read(input_audio_file)\n",
    "    Bit_Check = wave.open(input_audio_file, 'rb')\n",
    "    bit_depth = Bit_Check.getsampwidth() * 8\n",
    "    data = data / (2 ** (bit_depth - 1))\n",
    "    Overlaps = math.floor(len(data) / 128)\n",
    "    audio_ss = np.zeros(len(data))\n",
    "\n",
    "    for No_of_overlaps in range(Overlaps - 5):\n",
    "        Rectangular_windowed_signal = data[0 + 128 * No_of_overlaps:512 + 128 * No_of_overlaps]\n",
    "        Estimated_noise_PSD = np.zeros(N_fft)\n",
    "        GAN_noise_estimate = np.zeros(N_fft)\n",
    "        FFT_of_windowed_signal = hann_window_a_signal(Rectangular_windowed_signal)\n",
    "\n",
    "        Hann_window = sps.windows.hann(len(Rectangular_windowed_signal))\n",
    "        PSD_window_scaling = np.sum(Hann_window ** 2)\n",
    "        PSD_of_windowed_signal = (np.abs(FFT_of_windowed_signal) ** 2) / (samplerate * PSD_window_scaling)\n",
    "\n",
    "        Tensor_PSD = tf.convert_to_tensor(PSD_of_windowed_signal.reshape(1, 1024), tf.float32)\n",
    "        Generated_codebook = Noise_gan(Tensor_PSD)\n",
    "        Generated_codebook = Generated_codebook.numpy()\n",
    "        Generated_codebook_reshaped = np.abs((Generated_codebook.reshape(1024, 9)))\n",
    "\n",
    "        Generated_codebook_inverse = np.linalg.pinv(Generated_codebook_reshaped, rcond=1e-15)\n",
    "        Generated_coeffs = Generated_codebook_inverse * PSD_of_windowed_signal\n",
    "        Generated_coeffs = np.transpose(Generated_coeffs)\n",
    "        GAN_noise_codebook = (Generated_coeffs * Generated_codebook_reshaped)\n",
    "        GAN_noise_codebook = GAN_noise_codebook.clip(min=0)\n",
    "\n",
    "        for Freq_bin in range(0, N_fft):\n",
    "            GAN_noise_estimate[Freq_bin] = np.sum(GAN_noise_codebook[Freq_bin, :])\n",
    "\n",
    "        GAN_noise_estimate[512:1024] = np.flip(GAN_noise_estimate[0:512])\n",
    "        scalar_factor_noise = sum([psd_value for psd_value in GAN_noise_estimate])\n",
    "        GAN_noise_estimate_normalised = GAN_noise_estimate / scalar_factor_noise\n",
    "\n",
    "        snr = PSD_of_windowed_signal / (100 * GAN_noise_estimate)\n",
    "        Spectral_mask = 1 - np.minimum(1, np.maximum(0, alpha * snr))\n",
    "        Clean_signal = FFT_of_windowed_signal * Spectral_mask\n",
    "        Clean_frames = np.fft.ifft(Clean_signal)\n",
    "\n",
    "        audio_ss[0 + 128 * No_of_overlaps:512 + 128 * No_of_overlaps] = audio_ss[\n",
    "                                                                           0 + 128 * No_of_overlaps:512 + 128 * No_of_overlaps] + Clean_frames[0:512]\n",
    "\n",
    "    # Save the processed audio\n",
    "    sf.write(output_audio_file, audio_ss, samplerate, 'PCM_16')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pytorch.org/audio/0.13.1/tutorials/mvdr_tutorial.html\n",
    "\n",
    "SI-SNR less undesired interference or distortion (HIGHER MEANS MORE SIMILAR TO THE REFERENCE SPEECH)\n",
    "\n",
    "SDR means estimated speech contains more desired source signal and less undesired sources or noise (HIGHER FOR BETTER SPEECH QUALITY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 16000\n",
    "\n",
    "def si_snr(estimate, reference, epsilon=1e-8):\n",
    "    estimate = estimate - estimate.mean()\n",
    "    reference = reference - reference.mean()\n",
    "    reference_pow = reference.pow(2).mean(axis=1, keepdim=True)\n",
    "    mix_pow = (estimate * reference).mean(axis=1, keepdim=True)\n",
    "    scale = mix_pow / (reference_pow + epsilon)\n",
    "\n",
    "    reference = scale * reference\n",
    "    error = estimate - reference\n",
    "\n",
    "    reference_pow = reference.pow(2)\n",
    "    error_pow = error.pow(2)\n",
    "\n",
    "    reference_pow = reference_pow.mean(axis=1)\n",
    "    error_pow = error_pow.mean(axis=1)\n",
    "\n",
    "    si_snr = 10 * torch.log10(reference_pow) - 10 * torch.log10(error_pow)\n",
    "    return si_snr.item()\n",
    "\n",
    "def evaluate(estimate, reference):\n",
    "    try:\n",
    "        si_snr_score = si_snr(estimate, reference)\n",
    "        (\n",
    "            sdr,\n",
    "            _,\n",
    "            _,\n",
    "            _,\n",
    "        ) = mir_eval.separation.bss_eval_sources(reference.numpy(), estimate.numpy(), False)\n",
    "        pesq_mix = pesq(SAMPLE_RATE, estimate[0].numpy(), reference[0].numpy(), \"wb\")\n",
    "        stoi_mix = stoi(reference[0].numpy(), estimate[0].numpy(), SAMPLE_RATE, extended=False)\n",
    "        return pesq_mix, stoi_mix, sdr[0], si_snr_score\n",
    "    except NoUtterancesError as e:\n",
    "        return 0, 0  # Or any default values you prefer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the noise GAN model\n",
    "Noise_gan = tf.saved_model.load('../Spectogram/Full_Curriculum_4_generator')\n",
    "# Load the clean audio folders\n",
    "clean_audio_path = \"../Spectogram/SNR_seg/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For one speech\n",
    "#entries = ['speech_1000.wav']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['speech_413.wav', 'speech_556.wav', 'speech_751.wav']\n"
     ]
    }
   ],
   "source": [
    "# For spechifc amount of random speech\n",
    "num_test = 3\n",
    "# Create an empty array to store the random values\n",
    "entries = []\n",
    "\n",
    "# Generate 100 random values and append them to the list\n",
    "for _ in range(num_test):\n",
    "    random_value = random.randint(0, 824)\n",
    "    entries.append(random_value)\n",
    "\n",
    "# Sort the list in ascending order\n",
    "entries.sort()\n",
    "\n",
    "# Rename each item in the list to \"speech_number.wav\"\n",
    "for i in range(len(entries)):\n",
    "    entries[i] = \"speech_\" + str(entries[i]) + \".wav\"\n",
    "\n",
    "\n",
    "print(entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speech_1000: Alpha value: 0.00 Class: -9dB\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Edward\\AppData\\Local\\Temp\\ipykernel_13732\\3105023457.py:51: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  audio_ss[0 + 128 * No_of_overlaps:512 + 128 * No_of_overlaps] = audio_ss[\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speech_1000: Current SNR: 0dB, Alpha value: 2.00, Class: -3dB, PESQ: 1.1057612895965576, STOI: 0.48105509146517306\n",
      "speech_1000: Current SNR: -3dB, Alpha value: 2.00, Class: -3dB, PESQ: 1.1057612895965576, STOI: 0.48105509146517306\n",
      "speech_1000: Alpha value: 0.00 Class: -9dB\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\Fourth Year\\COMPSYS 700\\class_model_3\\Combine_test_alldB.ipynb Cell 14\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Fourth%20Year/COMPSYS%20700/class_model_3/Combine_test_alldB.ipynb#X14sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m: Alpha value: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m Class: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(edit_ent, \u001b[39m\"\u001b[39m\u001b[39m{:.2f}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(start_value), predicted_class), end\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\r\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Fourth%20Year/COMPSYS%20700/class_model_3/Combine_test_alldB.ipynb#X14sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m output_audio \u001b[39m=\u001b[39m new_ent_wav \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39mAlpha\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.wav\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39m\"\u001b[39m\u001b[39m{:.2f}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(start_value))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/Fourth%20Year/COMPSYS%20700/class_model_3/Combine_test_alldB.ipynb#X14sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m perform_gan_noise_subtraction(current_wav, output_audio, start_value, Noise_gan)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Fourth%20Year/COMPSYS%20700/class_model_3/Combine_test_alldB.ipynb#X14sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m create_spectrogram(output_audio, new_ent_img \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39mAlpha\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.png\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39m\"\u001b[39m\u001b[39m{:.2f}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(start_value)))\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Fourth%20Year/COMPSYS%20700/class_model_3/Combine_test_alldB.ipynb#X14sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m current_image \u001b[39m=\u001b[39m new_ent_img \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39mAlpha\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.png\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39m\"\u001b[39m\u001b[39m{:.2f}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(start_value))\n",
      "\u001b[1;32me:\\Fourth Year\\COMPSYS 700\\class_model_3\\Combine_test_alldB.ipynb Cell 14\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Fourth%20Year/COMPSYS%20700/class_model_3/Combine_test_alldB.ipynb#X14sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m Tensor_PSD \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconvert_to_tensor(PSD_of_windowed_signal\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m, \u001b[39m1024\u001b[39m), tf\u001b[39m.\u001b[39mfloat32)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Fourth%20Year/COMPSYS%20700/class_model_3/Combine_test_alldB.ipynb#X14sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m Generated_codebook \u001b[39m=\u001b[39m Noise_gan(Tensor_PSD)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/Fourth%20Year/COMPSYS%20700/class_model_3/Combine_test_alldB.ipynb#X14sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m Generated_codebook \u001b[39m=\u001b[39m Generated_codebook\u001b[39m.\u001b[39;49mnumpy()\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Fourth%20Year/COMPSYS%20700/class_model_3/Combine_test_alldB.ipynb#X14sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m Generated_codebook_reshaped \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mabs((Generated_codebook\u001b[39m.\u001b[39mreshape(\u001b[39m1024\u001b[39m, \u001b[39m9\u001b[39m)))\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Fourth%20Year/COMPSYS%20700/class_model_3/Combine_test_alldB.ipynb#X14sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m Generated_codebook_inverse \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mpinv(Generated_codebook_reshaped, rcond\u001b[39m=\u001b[39m\u001b[39m1e-15\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Edward\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1223\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1200\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[0;32m   1201\u001b[0m \n\u001b[0;32m   1202\u001b[0m \u001b[39mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1220\u001b[0m \u001b[39m    NumPy dtype.\u001b[39;00m\n\u001b[0;32m   1221\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1222\u001b[0m \u001b[39m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[1;32m-> 1223\u001b[0m maybe_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1224\u001b[0m \u001b[39mreturn\u001b[39;00m maybe_arr\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(maybe_arr, np\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m maybe_arr\n",
      "File \u001b[1;32mc:\\Users\\Edward\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1189\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1187\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_numpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m   1188\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1189\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy_internal()\n\u001b[0;32m   1190\u001b[0m   \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m     \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for ent in entries:\n",
    "    edit_ent = ent.replace(\".wav\", \"\")\n",
    "    for target in user_target:\n",
    "        os.makedirs(path_spec_test + \"{}/\".format(edit_ent + \"(\" + target + \")\") + \"spectrogram/\", exist_ok=True)\n",
    "        os.makedirs(path_spec_test + \"{}/\".format(edit_ent + \"(\" + target + \")\") + \"wav/\", exist_ok=True)\n",
    "        new_ent_img = path_spec_test + \"{}/\".format(edit_ent + \"(\" + target + \")\") + \"spectrogram/\"\n",
    "        new_ent_wav = path_spec_test + \"{}/\".format(edit_ent + \"(\" + target + \")\") + \"wav/\"\n",
    "        create_spectrogram(clean_audio_path + target + \"/\" + ent, new_ent_img + 'Default.png')\n",
    "        create_spectrogram(clean_audio_path + \"clean/\" + ent, new_ent_img + 'clean.png')\n",
    "        current_image = new_ent_img + 'Default.png'\n",
    "        current_wav = clean_audio_path + target + \"/\" + ent\n",
    "        audio_clean = False\n",
    "        stop_value = 2\n",
    "        start_value = 0\n",
    "        clean_wav = clean_audio_path + \"clean/\" + ent\n",
    "        counter = 0\n",
    "\n",
    "        STOI_Highest = 0\n",
    "        PESQ_Highest = 0\n",
    "        \n",
    "        while(audio_clean == False and start_value < stop_value):\n",
    "            counter += 1\n",
    "            # Preprocess the image\n",
    "            image = img_to_array(load_img(current_image, target_size=(224, 224, 3)))\n",
    "            image = image / 255.0\n",
    "            image = np.expand_dims(image, axis=0)\n",
    "\n",
    "            # Make predictions\n",
    "            predictions = new_model.predict(image)\n",
    "            # Find the index of the maximum prediction\n",
    "            predicted_index = np.argmax(predictions)\n",
    "            # Check if the predicted class matches the target\n",
    "            predicted_class = target_names[predicted_index]\n",
    "\n",
    "            start_value = round(start_value, 2)\n",
    "            print(\"{}: Alpha value: {} Class: {}\".format(edit_ent, \"{:.2f}\".format(start_value), predicted_class), end=\"\\r\")\n",
    "            output_audio = new_ent_wav + 'Alpha{}.wav'.format(\"{:.2f}\".format(start_value))\n",
    "            perform_gan_noise_subtraction(current_wav, output_audio, start_value, Noise_gan)\n",
    "            create_spectrogram(output_audio, new_ent_img + 'Alpha{}.png'.format(\"{:.2f}\".format(start_value)))\n",
    "            current_image = new_ent_img + 'Alpha{}.png'.format(\"{:.2f}\".format(start_value))\n",
    "            \n",
    "            SAMPLE_CLEAN = clean_wav\n",
    "            SAMPLE_NOISY = output_audio\n",
    "            waveform_clean, sr = torchaudio.load(SAMPLE_CLEAN)\n",
    "            waveform_noisy, sr2 = torchaudio.load(SAMPLE_NOISY)\n",
    "\n",
    "            PESQ, STOI, SDR, SI_SNR_SCORE = evaluate(waveform_noisy[0:1], waveform_clean[0:1])\n",
    "\n",
    "            if STOI > STOI_Highest:\n",
    "                STOI_Highest = STOI\n",
    "                STOI_saved = i \n",
    "            if PESQ > PESQ_Highest:\n",
    "                PESQ_Highest = PESQ\n",
    "                PESQ_saved = i\n",
    "\n",
    "            workfile1 = openpyxl.load_workbook(ex_path)\n",
    "            sheet1 = workfile1.active\n",
    "\n",
    "            sheet1.cell(row=i+2, column=1).value = counter\n",
    "            sheet1.cell(row=i+2, column=2).value = edit_ent\n",
    "            sheet1.cell(row=i+2, column=3).value = target\n",
    "            sheet1.cell(row=i+2, column=4).value = start_value\n",
    "            sheet1.cell(row=i+2, column=5).value = predicted_class\n",
    "            sheet1.cell(row=i+2, column=6).value = PESQ\n",
    "            sheet1.cell(row=i+2, column=7).value = STOI\n",
    "            sheet1.cell(row=i+2, column=8).value = SDR\n",
    "            sheet1.cell(row=i+2, column=9).value = SI_SNR_SCORE\n",
    "            workfile1.save(ex_path)\n",
    "            i += 1\n",
    "\n",
    "            if predicted_class in clean:\n",
    "                audio_clean = True\n",
    "            else: \n",
    "                start_value += 0.05\n",
    "\n",
    "        workfile1 = openpyxl.load_workbook(ex_path)\n",
    "        sheet1 = workfile1.active\n",
    "\n",
    "        sheet1.cell(row=PESQ_saved+2, column=10).value = PESQ_Highest\n",
    "        sheet1.cell(row=STOI_saved+2, column=11).value = STOI_Highest\n",
    "\n",
    "        workfile1.save(ex_path)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "        print(\"{}: Current SNR: {}, Alpha value: {}, Class: {}, PESQ: {}, STOI: {}\".format(edit_ent, target, \"{:.2f}\".format(start_value), predicted_class, PESQ, STOI))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spectral attenuate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
