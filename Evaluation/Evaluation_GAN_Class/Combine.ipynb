{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1+cpu\n",
      "2.0.2+cpu\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import scipy.signal as sps\n",
    "import soundfile as sf\n",
    "import os\n",
    "import math\n",
    "import wave\n",
    "from scipy.io import wavfile\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "import xlsxwriter\n",
    "import openpyxl\n",
    "\n",
    "from pesq import pesq, NoUtterancesError\n",
    "from pystoi import stoi\n",
    "import mir_eval\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "from torchaudio.utils import download_asset\n",
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.functional as F\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchaudio.__version__)\n",
    "\n",
    "%matplotlib inline\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "if physical_devices:\n",
    "  tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spectrogram(audio_file, image_file):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1)\n",
    "\n",
    "    y, sr = librosa.load(audio_file)\n",
    "    ms = librosa.feature.melspectrogram(y=y, sr=sr, S=None, n_fft=1024, hop_length=80, win_length=320, window='hann', center=True, pad_mode='constant', power=2.0)\n",
    "    #ms = librosa.feature.melspectrogram(y=y, sr=sr, S=None)\n",
    "    log_ms = librosa.power_to_db(ms, ref=np.max)\n",
    "    librosa.display.specshow(log_ms, sr=sr)\n",
    "\n",
    "    fig.savefig(image_file)\n",
    "    plt.close(fig)\n",
    "    \n",
    "def create_pngs_from_wavs(input_path, output_path):\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "\n",
    "    dir = os.listdir(input_path)\n",
    "\n",
    "    for i, file in enumerate(dir):\n",
    "        input_file = os.path.join(input_path, file)\n",
    "        output_file = os.path.join(output_path, file.replace('.wav', '.png'))\n",
    "        create_spectrogram(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_path(path, label, limit=1500):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    file_list = os.listdir(path)\n",
    "    if limit is not None:\n",
    "        file_list = file_list[:limit]\n",
    "\n",
    "    for file in file_list:\n",
    "        images.append(img_to_array(load_img(os.path.join(path, file), target_size=(224, 224, 3))))\n",
    "        labels.append(label)\n",
    "        \n",
    "    return images, labels\n",
    "\n",
    "def show_images(images):\n",
    "    fig, axes = plt.subplots(1, 8, figsize=(20, 20), subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        ax.imshow(images[i] / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 111, 111, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 109, 109, 128)     36992     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 54, 54, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 52, 52, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 26, 26, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 24, 24, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 12, 12, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 18432)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              18875392  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 8200      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,216,648\n",
      "Trainable params: 19,216,648\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Recreate the exact same model, including its weights and the optimizer\n",
    "new_model = tf.keras.models.load_model('models/my_model.h5')\n",
    "\n",
    "# Show the model architecture\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# All locations\n",
    "folder_name = \"data_test_test/\"\n",
    "entries = os.listdir(folder_name)\n",
    "print(len(entries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the %s directory is created! Spectrograms_wide_VA/Spectral_subtract_new_model/\n"
     ]
    }
   ],
   "source": [
    "path = \"Spectrograms_wide_VA\"\n",
    "\n",
    "path_spec_test = path + \"/Spectral_subtract_new_model/\"\n",
    "\n",
    "isExist = os.path.exists(path_spec_test)\n",
    "if not isExist:\n",
    "    # Create a new directory because it does not exist\n",
    "    os.makedirs(path_spec_test)\n",
    "    print(\"the %s directory is created!\", path_spec_test)\n",
    "\n",
    "noisy = [\"-3dB\", \"-6dB\", \"-9dB\", \"0dB\"]\n",
    "clean = [\"3dB\", \"6dB\", \"9dB\", \"clean\"]\n",
    "target_names = [\"clean\", \"0dB\", \"-3dB\", \"-6dB\", \"-9dB\", \"3dB\", \"6dB\", \"9dB\"]\n",
    "user_target = [\"0dB\", \"-3dB\", \"-6dB\", \"-9dB\", \"3dB\", \"6dB\", \"9dB\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_path = path_spec_test + \"/combine.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The excel file 1 is created!\n"
     ]
    }
   ],
   "source": [
    "isExist3 = os.path.exists(ex_path)\n",
    "if not isExist3:\n",
    "   workbook1 = xlsxwriter.Workbook(ex_path)\n",
    "   worksheet1 = workbook1.add_worksheet()\n",
    "   worksheet1.write(0, 0, \"Number\")\n",
    "   worksheet1.write(0, 1, \"Name\")\n",
    "   worksheet1.write(0, 2, \"Alpha Value\")\n",
    "   worksheet1.write(0, 3, \"SNR(dB)\")\n",
    "   worksheet1.write(0, 4, \"PESQ Evaluation\")\n",
    "   worksheet1.write(0, 5, \"STOI Evaluation\")\n",
    "   worksheet1.write(0, 6, \"PESQ Highest\")\n",
    "   worksheet1.write(0, 7, \"STOI Highest\")\n",
    "   print(\"The excel file 1 is created!\")\n",
    "   workbook1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hann_window_a_signal(Windowed_data):\n",
    "    Hann_window = sps.windows.hann(len(Windowed_data))\n",
    "    Hann_Windowed_data = Hann_window * Windowed_data\n",
    "    padded_signal = np.pad(Hann_Windowed_data, (0, 512), 'constant')\n",
    "    Windowed_data_fft = np.fft.fft(padded_signal, 1024)\n",
    "    return Windowed_data_fft\n",
    "\n",
    "def perform_gan_noise_subtraction(input_audio_file, output_audio_file, alpha, Noise_gan):\n",
    "    N_fft = 1024\n",
    "\n",
    "    samplerate, data = wavfile.read(input_audio_file)\n",
    "    Bit_Check = wave.open(input_audio_file, 'rb')\n",
    "    bit_depth = Bit_Check.getsampwidth() * 8\n",
    "    data = data / (2 ** (bit_depth - 1))\n",
    "    Overlaps = math.floor(len(data) / 128)\n",
    "    audio_ss = np.zeros(len(data))\n",
    "\n",
    "    for No_of_overlaps in range(Overlaps - 5):\n",
    "        Rectangular_windowed_signal = data[0 + 128 * No_of_overlaps:512 + 128 * No_of_overlaps]\n",
    "        Estimated_noise_PSD = np.zeros(N_fft)\n",
    "        GAN_noise_estimate = np.zeros(N_fft)\n",
    "        FFT_of_windowed_signal = hann_window_a_signal(Rectangular_windowed_signal)\n",
    "\n",
    "        Hann_window = sps.windows.hann(len(Rectangular_windowed_signal))\n",
    "        PSD_window_scaling = np.sum(Hann_window ** 2)\n",
    "        PSD_of_windowed_signal = (np.abs(FFT_of_windowed_signal) ** 2) / (samplerate * PSD_window_scaling)\n",
    "\n",
    "        Tensor_PSD = tf.convert_to_tensor(PSD_of_windowed_signal.reshape(1, 1024), tf.float32)\n",
    "        Generated_codebook = Noise_gan(Tensor_PSD)\n",
    "        Generated_codebook = Generated_codebook.numpy()\n",
    "        Generated_codebook_reshaped = np.abs((Generated_codebook.reshape(1024, 9)))\n",
    "\n",
    "        Generated_codebook_inverse = np.linalg.pinv(Generated_codebook_reshaped, rcond=1e-15)\n",
    "        Generated_coeffs = Generated_codebook_inverse * PSD_of_windowed_signal\n",
    "        Generated_coeffs = np.transpose(Generated_coeffs)\n",
    "        GAN_noise_codebook = (Generated_coeffs * Generated_codebook_reshaped)\n",
    "        GAN_noise_codebook = GAN_noise_codebook.clip(min=0)\n",
    "\n",
    "        for Freq_bin in range(0, N_fft):\n",
    "            GAN_noise_estimate[Freq_bin] = np.sum(GAN_noise_codebook[Freq_bin, :])\n",
    "\n",
    "        GAN_noise_estimate[512:1024] = np.flip(GAN_noise_estimate[0:512])\n",
    "        scalar_factor_noise = sum([psd_value for psd_value in GAN_noise_estimate])\n",
    "        GAN_noise_estimate_normalised = GAN_noise_estimate / scalar_factor_noise\n",
    "\n",
    "        snr = PSD_of_windowed_signal / (100 * GAN_noise_estimate)\n",
    "        Spectral_mask = 1 - np.minimum(1, np.maximum(0, alpha * snr))\n",
    "        Clean_signal = FFT_of_windowed_signal * Spectral_mask\n",
    "        Clean_frames = np.fft.ifft(Clean_signal)\n",
    "\n",
    "        audio_ss[0 + 128 * No_of_overlaps:512 + 128 * No_of_overlaps] = audio_ss[\n",
    "                                                                           0 + 128 * No_of_overlaps:512 + 128 * No_of_overlaps] + Clean_frames[0:512]\n",
    "\n",
    "    # Save the processed audio\n",
    "    sf.write(output_audio_file, audio_ss, samplerate, 'PCM_16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 16000\n",
    "\n",
    "def evaluate(estimate, reference):\n",
    "    try:\n",
    "        pesq_mix = pesq(SAMPLE_RATE, estimate[0].numpy(), reference[0].numpy(), \"wb\")\n",
    "        stoi_mix = stoi(reference[0].numpy(), estimate[0].numpy(), SAMPLE_RATE, extended=False)\n",
    "        return pesq_mix, stoi_mix\n",
    "    except NoUtterancesError as e:\n",
    "        return 0, 0  # Or any default values you prefer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speech_1: Alpha value: 0.00 Class: -3dB\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Edward\\AppData\\Local\\Temp\\ipykernel_20980\\3105023457.py:51: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  audio_ss[0 + 128 * No_of_overlaps:512 + 128 * No_of_overlaps] = audio_ss[\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speech_1: Alpha value: 0.45 Class: 3dB, PESQ: 1.5810961723327637, STOI: 0.666970109174097\n",
      "speech_2: Alpha value: 0.85 Class: 3dB, PESQ: 1.0374547243118286, STOI: 0.5272606778138093\n",
      "speech_3: Alpha value: 0.50 Class: 3dB, PESQ: 1.1301944255828857, STOI: 0.6834830034534183\n"
     ]
    }
   ],
   "source": [
    "# Load the noise GAN model\n",
    "Noise_gan = tf.saved_model.load('../Spectogram/Full_Curriculum_4_generator')\n",
    "# Load the clean audio folders\n",
    "clean_audio_path = \"../Spectogram/SNR_seg/clean/\"\n",
    "i = 0\n",
    "for ent in entries:\n",
    "    edit_ent = ent.replace(\".wav\", \"\")\n",
    "    os.makedirs(path_spec_test + \"{}/\".format(edit_ent) + \"spectrogram/\", exist_ok=True)\n",
    "    os.makedirs(path_spec_test + \"{}/\".format(edit_ent) + \"wav/\", exist_ok=True)\n",
    "    new_ent_img = path_spec_test + \"{}/\".format(edit_ent) + \"spectrogram/\"\n",
    "    new_ent_wav = path_spec_test + \"{}/\".format(edit_ent) + \"wav/\"\n",
    "    create_spectrogram(folder_name + ent, new_ent_img + 'Default.png')\n",
    "    create_spectrogram(clean_audio_path + ent, new_ent_img + 'clean.png')\n",
    "    current_image = new_ent_img + 'Default.png'\n",
    "    current_wav = folder_name + ent\n",
    "    audio_clean = False\n",
    "    stop_value = 2\n",
    "    start_value = 0\n",
    "    clean_wav = clean_audio_path + ent\n",
    "    counter = 0\n",
    "\n",
    "    STOI_Highest = 0\n",
    "    PESQ_Highest = 0\n",
    "    \n",
    "    while(audio_clean == False and start_value < stop_value):\n",
    "        counter += 1\n",
    "        # Preprocess the image\n",
    "        image = img_to_array(load_img(current_image, target_size=(224, 224, 3)))\n",
    "        image = image / 255.0\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "\n",
    "        # Make predictions\n",
    "        predictions = new_model.predict(image)\n",
    "        # Find the index of the maximum prediction\n",
    "        predicted_index = np.argmax(predictions)\n",
    "        # Check if the predicted class matches the target\n",
    "        predicted_class = target_names[predicted_index]\n",
    "\n",
    "        start_value = round(start_value, 2)\n",
    "        print(\"{}: Alpha value: {} Class: {}\".format(edit_ent, \"{:.2f}\".format(start_value), predicted_class), end=\"\\r\")\n",
    "        output_audio = new_ent_wav + 'Alpha{}.wav'.format(\"{:.2f}\".format(start_value))\n",
    "        perform_gan_noise_subtraction(current_wav, output_audio, start_value, Noise_gan)\n",
    "        create_spectrogram(output_audio, new_ent_img + 'Alpha{}.png'.format(\"{:.2f}\".format(start_value)))\n",
    "        current_image = new_ent_img + 'Alpha{}.png'.format(\"{:.2f}\".format(start_value))\n",
    "        \n",
    "        SAMPLE_CLEAN = clean_wav\n",
    "        SAMPLE_NOISY = output_audio\n",
    "        waveform_clean, sr = torchaudio.load(SAMPLE_CLEAN)\n",
    "        waveform_noisy, sr2 = torchaudio.load(SAMPLE_NOISY)\n",
    "\n",
    "        PESQ, STOI = evaluate(waveform_noisy[0:1], waveform_clean[0:1])\n",
    "\n",
    "        if STOI > STOI_Highest:\n",
    "            STOI_Highest = STOI\n",
    "            STOI_saved = i \n",
    "        if PESQ > PESQ_Highest:\n",
    "            PESQ_Highest = PESQ\n",
    "            PESQ_saved = i\n",
    "\n",
    "        workfile1 = openpyxl.load_workbook(ex_path)\n",
    "        sheet1 = workfile1.active\n",
    "\n",
    "        sheet1.cell(row=i+2, column=1).value = counter\n",
    "        sheet1.cell(row=i+2, column=2).value = edit_ent\n",
    "        sheet1.cell(row=i+2, column=3).value = start_value\n",
    "        sheet1.cell(row=i+2, column=4).value = predicted_class\n",
    "        sheet1.cell(row=i+2, column=5).value = PESQ\n",
    "        sheet1.cell(row=i+2, column=6).value = STOI\n",
    "\n",
    "        workfile1.save(ex_path)\n",
    "        i += 1\n",
    "\n",
    "        if predicted_class in clean:\n",
    "            audio_clean = True\n",
    "        else: \n",
    "            start_value += 0.05\n",
    "\n",
    "    workfile1 = openpyxl.load_workbook(ex_path)\n",
    "    sheet1 = workfile1.active\n",
    "\n",
    "    sheet1.cell(row=PESQ_saved+2, column=7).value = PESQ_Highest\n",
    "    sheet1.cell(row=STOI_saved+2, column=8).value = STOI_Highest\n",
    "\n",
    "    workfile1.save(ex_path)\n",
    "\n",
    "    i += 1\n",
    "\n",
    "    print(\"{}: Alpha value: {} Class: {}, PESQ: {}, STOI: {}\".format(edit_ent, \"{:.2f}\".format(start_value), predicted_class, PESQ, STOI))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spectral attenuate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
