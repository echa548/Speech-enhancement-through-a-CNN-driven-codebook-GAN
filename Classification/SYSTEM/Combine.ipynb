{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import scipy.signal as sps\n",
    "import soundfile as sf\n",
    "import os\n",
    "import math\n",
    "import wave\n",
    "from scipy.io import wavfile\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "\n",
    "%matplotlib inline\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "if physical_devices:\n",
    "  tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spectrogram(audio_file, image_file):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1)\n",
    "\n",
    "    y, sr = librosa.load(audio_file)\n",
    "    ms = librosa.feature.melspectrogram(y=y, sr=sr, S=None, n_fft=1024, hop_length=80, win_length=320, window='hann', center=True, pad_mode='constant', power=2.0)\n",
    "    #ms = librosa.feature.melspectrogram(y=y, sr=sr, S=None)\n",
    "    log_ms = librosa.power_to_db(ms, ref=np.max)\n",
    "    librosa.display.specshow(log_ms, sr=sr)\n",
    "\n",
    "    fig.savefig(image_file)\n",
    "    plt.close(fig)\n",
    "    \n",
    "def create_pngs_from_wavs(input_path, output_path):\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "\n",
    "    dir = os.listdir(input_path)\n",
    "\n",
    "    for i, file in enumerate(dir):\n",
    "        input_file = os.path.join(input_path, file)\n",
    "        output_file = os.path.join(output_path, file.replace('.wav', '.png'))\n",
    "        create_spectrogram(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_path(path, label, limit=1500):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    file_list = os.listdir(path)\n",
    "    if limit is not None:\n",
    "        file_list = file_list[:limit]\n",
    "\n",
    "    for file in file_list:\n",
    "        images.append(img_to_array(load_img(os.path.join(path, file), target_size=(224, 224, 3))))\n",
    "        labels.append(label)\n",
    "        \n",
    "    return images, labels\n",
    "\n",
    "def show_images(images):\n",
    "    fig, axes = plt.subplots(1, 8, figsize=(20, 20), subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        ax.imshow(images[i] / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 111, 111, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 109, 109, 128)     36992     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 54, 54, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 52, 52, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 26, 26, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 24, 24, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 12, 12, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 18432)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              18875392  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 8200      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,216,648\n",
      "Trainable params: 19,216,648\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Recreate the exact same model, including its weights and the optimizer\n",
    "new_model = tf.keras.models.load_model('models/my_model.h5')\n",
    "\n",
    "# Show the model architecture\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "# All locations\n",
    "folder_name = \"data_test/\"\n",
    "entries = os.listdir(folder_name)\n",
    "print(len(entries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['speech_1.wav', 'speech_10.wav']\n"
     ]
    }
   ],
   "source": [
    "print(entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the %s directory is created! Spectrograms_wide_VA/Spectral_subtract_test2/\n"
     ]
    }
   ],
   "source": [
    "path = \"Spectrograms_wide_VA\"\n",
    "\n",
    "path_spec_test = path + \"/Spectral_subtract_test2/\"\n",
    "\n",
    "isExist = os.path.exists(path_spec_test)\n",
    "if not isExist:\n",
    "    # Create a new directory because it does not exist\n",
    "    os.makedirs(path_spec_test)\n",
    "    print(\"the %s directory is created!\", path_spec_test)\n",
    "\n",
    "noisy = [\"-3dB\", \"-6dB\", \"-9dB\"]\n",
    "clean = [\"0dB\", \"3dB\", \"6dB\", \"9dB\", \"clean\"]\n",
    "target_names = [\"clean\", \"0dB\", \"-3dB\", \"-6dB\", \"-9dB\", \"3dB\", \"6dB\", \"9dB\"]\n",
    "user_target = [\"0dB\", \"-3dB\", \"-6dB\", \"-9dB\", \"3dB\", \"6dB\", \"9dB\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hann_window_a_signal(Windowed_data):\n",
    "    Hann_window = sps.windows.hann(len(Windowed_data))\n",
    "    Hann_Windowed_data = Hann_window * Windowed_data\n",
    "    padded_signal = np.pad(Hann_Windowed_data, (0, 512), 'constant')\n",
    "    Windowed_data_fft = np.fft.fft(padded_signal, 1024)\n",
    "    return Windowed_data_fft\n",
    "\n",
    "def perform_gan_noise_subtraction(input_audio_file, output_audio_file, alpha, Noise_gan):\n",
    "    N_fft = 1024\n",
    "\n",
    "    samplerate, data = wavfile.read(input_audio_file)\n",
    "    Bit_Check = wave.open(input_audio_file, 'rb')\n",
    "    bit_depth = Bit_Check.getsampwidth() * 8\n",
    "    data = data / (2 ** (bit_depth - 1))\n",
    "    Overlaps = math.floor(len(data) / 128)\n",
    "    audio_ss = np.zeros(len(data))\n",
    "\n",
    "    for No_of_overlaps in range(Overlaps - 5):\n",
    "        Rectangular_windowed_signal = data[0 + 128 * No_of_overlaps:512 + 128 * No_of_overlaps]\n",
    "        Estimated_noise_PSD = np.zeros(N_fft)\n",
    "        GAN_noise_estimate = np.zeros(N_fft)\n",
    "        FFT_of_windowed_signal = hann_window_a_signal(Rectangular_windowed_signal)\n",
    "\n",
    "        Hann_window = sps.windows.hann(len(Rectangular_windowed_signal))\n",
    "        PSD_window_scaling = np.sum(Hann_window ** 2)\n",
    "        PSD_of_windowed_signal = (np.abs(FFT_of_windowed_signal) ** 2) / (samplerate * PSD_window_scaling)\n",
    "\n",
    "        Tensor_PSD = tf.convert_to_tensor(PSD_of_windowed_signal.reshape(1, 1024), tf.float32)\n",
    "        Generated_codebook = Noise_gan(Tensor_PSD)\n",
    "        Generated_codebook = Generated_codebook.numpy()\n",
    "        Generated_codebook_reshaped = np.abs((Generated_codebook.reshape(1024, 9)))\n",
    "\n",
    "        Generated_codebook_inverse = np.linalg.pinv(Generated_codebook_reshaped, rcond=1e-15)\n",
    "        Generated_coeffs = Generated_codebook_inverse * PSD_of_windowed_signal\n",
    "        Generated_coeffs = np.transpose(Generated_coeffs)\n",
    "        GAN_noise_codebook = (Generated_coeffs * Generated_codebook_reshaped)\n",
    "        GAN_noise_codebook = GAN_noise_codebook.clip(min=0)\n",
    "\n",
    "        for Freq_bin in range(0, N_fft):\n",
    "            GAN_noise_estimate[Freq_bin] = np.sum(GAN_noise_codebook[Freq_bin, :])\n",
    "\n",
    "        GAN_noise_estimate[512:1024] = np.flip(GAN_noise_estimate[0:512])\n",
    "        scalar_factor_noise = sum([psd_value for psd_value in GAN_noise_estimate])\n",
    "        GAN_noise_estimate_normalised = GAN_noise_estimate / scalar_factor_noise\n",
    "\n",
    "        snr = PSD_of_windowed_signal / (100 * GAN_noise_estimate)\n",
    "        Spectral_mask = 1 - np.minimum(1, np.maximum(0, alpha * snr))\n",
    "        Clean_signal = FFT_of_windowed_signal * Spectral_mask\n",
    "        Clean_frames = np.fft.ifft(Clean_signal)\n",
    "\n",
    "        audio_ss[0 + 128 * No_of_overlaps:512 + 128 * No_of_overlaps] = audio_ss[\n",
    "                                                                           0 + 128 * No_of_overlaps:512 + 128 * No_of_overlaps] + Clean_frames[0:512]\n",
    "\n",
    "    # Save the processed audio\n",
    "    sf.write(output_audio_file, audio_ss, samplerate, 'PCM_16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speech_1: Alpha value: 0.05 Class: -9dB\r"
     ]
    },
    {
     "ename": "UFuncTypeError",
     "evalue": "ufunc 'multiply' did not contain a loop with signature matching types (dtype('<U4'), dtype('float64')) -> None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32me:\\Fourth Year\\COMPSYS 700\\class_model_3\\Combine.ipynb Cell 9\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Fourth%20Year/COMPSYS%20700/class_model_3/Combine.ipynb#X14sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m: Alpha value: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m Class: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(edit_ent, start_value, predicted_class), end\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\r\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Fourth%20Year/COMPSYS%20700/class_model_3/Combine.ipynb#X14sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m output_audio \u001b[39m=\u001b[39m new_ent_wav \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39mAlpha\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.wav\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(start_value)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/Fourth%20Year/COMPSYS%20700/class_model_3/Combine.ipynb#X14sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m perform_gan_noise_subtraction(current_wav, output_audio, start_value, Noise_gan)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Fourth%20Year/COMPSYS%20700/class_model_3/Combine.ipynb#X14sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m create_spectrogram(output_audio, new_ent_img \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39mAlpha\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.png\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(start_value))\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Fourth%20Year/COMPSYS%20700/class_model_3/Combine.ipynb#X14sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m current_image \u001b[39m=\u001b[39m new_ent_img \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39mAlpha\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.png\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(start_value)\n",
      "\u001b[1;32me:\\Fourth Year\\COMPSYS 700\\class_model_3\\Combine.ipynb Cell 9\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Fourth%20Year/COMPSYS%20700/class_model_3/Combine.ipynb#X14sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m GAN_noise_estimate_normalised \u001b[39m=\u001b[39m GAN_noise_estimate \u001b[39m/\u001b[39m scalar_factor_noise\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Fourth%20Year/COMPSYS%20700/class_model_3/Combine.ipynb#X14sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m snr \u001b[39m=\u001b[39m PSD_of_windowed_signal \u001b[39m/\u001b[39m (\u001b[39m100\u001b[39m \u001b[39m*\u001b[39m GAN_noise_estimate)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/Fourth%20Year/COMPSYS%20700/class_model_3/Combine.ipynb#X14sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m Spectral_mask \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39m-\u001b[39m np\u001b[39m.\u001b[39mminimum(\u001b[39m1\u001b[39m, np\u001b[39m.\u001b[39mmaximum(\u001b[39m0\u001b[39m, alpha \u001b[39m*\u001b[39;49m snr))\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Fourth%20Year/COMPSYS%20700/class_model_3/Combine.ipynb#X14sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m Clean_signal \u001b[39m=\u001b[39m FFT_of_windowed_signal \u001b[39m*\u001b[39m Spectral_mask\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Fourth%20Year/COMPSYS%20700/class_model_3/Combine.ipynb#X14sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m Clean_frames \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mfft\u001b[39m.\u001b[39mifft(Clean_signal)\n",
      "\u001b[1;31mUFuncTypeError\u001b[0m: ufunc 'multiply' did not contain a loop with signature matching types (dtype('<U4'), dtype('float64')) -> None"
     ]
    }
   ],
   "source": [
    "# Load the noise GAN model\n",
    "Noise_gan = tf.saved_model.load('../Spectogram/Noise_PSD_Generator_epoch_73')\n",
    "\n",
    "for ent in entries:\n",
    "    edit_ent = ent.replace(\".wav\", \"\")\n",
    "    os.makedirs(path_spec_test + \"{}/\".format(edit_ent) + \"spectrogram/\", exist_ok=True)\n",
    "    os.makedirs(path_spec_test + \"{}/\".format(edit_ent) + \"wav/\", exist_ok=True)\n",
    "    new_ent_img = path_spec_test + \"{}/\".format(edit_ent) + \"spectrogram/\"\n",
    "    new_ent_wav = path_spec_test + \"{}/\".format(edit_ent) + \"wav/\"\n",
    "    create_spectrogram(folder_name + ent, new_ent_img + 'Default.png')\n",
    "    current_image = new_ent_img + 'Default.png'\n",
    "    current_wav = folder_name + ent\n",
    "    audio_clean = False\n",
    "    stop_value = 2\n",
    "    start_value = 0\n",
    "\n",
    "\n",
    "    while(audio_clean == False and start_value < stop_value):\n",
    "        # Preprocess the image\n",
    "        image = img_to_array(load_img(current_image, target_size=(224, 224, 3)))\n",
    "        image = image / 255.0\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "\n",
    "        # Make predictions\n",
    "        predictions = new_model.predict(image)\n",
    "        # Find the index of the maximum prediction\n",
    "        predicted_index = np.argmax(predictions)\n",
    "        # Check if the predicted class matches the target\n",
    "        predicted_class = target_names[predicted_index]\n",
    "\n",
    "        if predicted_class in clean:\n",
    "            audio_clean = True\n",
    "        else:\n",
    "            start_value += 0.05\n",
    "            start_value = round(start_value, 2)\n",
    "            print(\"{}: Alpha value: {} Class: {}\".format(edit_ent, \"{:.2f}\".format(start_value), predicted_class), end=\"\\r\")\n",
    "            output_audio = new_ent_wav + 'Alpha{}.wav'.format(\"{:.2f}\".format(start_value))\n",
    "            perform_gan_noise_subtraction(current_wav, output_audio, start_value, Noise_gan)\n",
    "            create_spectrogram(output_audio, new_ent_img + 'Alpha{}.png'.format(\"{:.2f}\".format(start_value)))\n",
    "            current_image = new_ent_img + 'Alpha{}.png'.format(\"{:.2f}\".format(start_value))\n",
    "\n",
    "    print(\"{}: Alpha value: {} Class: {}\".format(edit_ent, \"{:.2f}\".format(start_value), predicted_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Noise_gan = tf.saved_model.load('../Spectogram/Noise_PSD_Generator_epoch_73')\n",
    "\n",
    "N_fft = 1024\n",
    "\n",
    "def Hann_window_a_signal(Windowed_data):\n",
    " Hann_window = sps.windows.hann(len(Windowed_data))\n",
    " Hann_Windowed_data = Hann_window*Windowed_data\n",
    " padded_signal = np.pad(Hann_Windowed_data,(0,512), 'constant')\n",
    "\n",
    " Windowed_data_fft = np.fft.fft(padded_signal,1024)\n",
    " return Windowed_data_fft\n",
    "\n",
    "# Define parameters and variables\n",
    "No_of_data_to_filter = 1\n",
    "num_samples = 1024\n",
    "fstep = 16000/1024\n",
    "f = np.linspace(0, (num_samples-1)*fstep, num_samples)\n",
    "\n",
    "targets = [3, 6, 9, 0, -3, -6, -9]\n",
    "\n",
    "for folder in range (0,len(targets)):\n",
    "    directory = str(targets[folder])+'dB'\n",
    "    path = os.path.join('../Spectogram/Filter_outputs/Spectral_subtract',directory) \n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "\n",
    "for target_db in range(0, len(targets)):\n",
    "    Path_of_noisy_mixture = '../Spectogram/SNR_seg/' + str(targets[target_db]) + 'dB' + '/'\n",
    "    directories = os.listdir('../Spectogram/SNR_seg/-6dB')\n",
    "\n",
    "    for No_of_data in range(0, No_of_data_to_filter):\n",
    "        samplerate, data = wavfile.read(Path_of_noisy_mixture + directories[No_of_data])\n",
    "        Bit_Check = wave.open(Path_of_noisy_mixture + directories[No_of_data], 'rb')\n",
    "        bit_depth = Bit_Check.getsampwidth() * 8\n",
    "        data = data / (2**(bit_depth-1))\n",
    "        Overlaps = math.floor(len(data) / 128)\n",
    "        audio_ss = np.zeros(len(data))\n",
    "\n",
    "        for No_of_overlaps in range(Overlaps - 5):\n",
    "            Rectangular_windowed_signal = data[0 + 128*No_of_overlaps:512 + 128*No_of_overlaps]\n",
    "            Estimated_noise_PSD = np.zeros(N_fft)\n",
    "            GAN_noise_estimate = np.zeros(N_fft)\n",
    "            FFT_of_windowed_signal = Hann_window_a_signal(Rectangular_windowed_signal)\n",
    "\n",
    "            Hann_window = sps.windows.hann(len(Rectangular_windowed_signal))\n",
    "            PSD_window_scaling = np.sum(Hann_window**2)\n",
    "            PSD_of_windowed_signal = (np.abs(FFT_of_windowed_signal)**2)/(samplerate*PSD_window_scaling)\n",
    "\n",
    "            Tensor_PSD = tf.convert_to_tensor(PSD_of_windowed_signal.reshape(1,1024), tf.float32)\n",
    "            Generated_codebook = Noise_gan(Tensor_PSD)\n",
    "            Generated_codebook = Generated_codebook.numpy()\n",
    "            Generated_codebook_reshaped = np.abs((Generated_codebook.reshape(1024,9)))\n",
    "\n",
    "            Generated_codebook_inverse = np.linalg.pinv(Generated_codebook_reshaped, rcond=1e-15)\n",
    "            Generated_coeffs = Generated_codebook_inverse*PSD_of_windowed_signal\n",
    "            Generated_coeffs = np.transpose(Generated_coeffs)\n",
    "            GAN_noise_codebook = (Generated_coeffs*Generated_codebook_reshaped)\n",
    "            GAN_noise_codebook = GAN_noise_codebook.clip(min=0)\n",
    "\n",
    "            \n",
    "            for Freq_bin in range (0,N_fft):\n",
    "                GAN_noise_estimate[Freq_bin]=np.sum(GAN_noise_codebook[Freq_bin,:])\n",
    "                # Spectral Subtraction (You can modify alpha as needed)\n",
    "\n",
    "            GAN_noise_estimate[512:1024]=np.flip(GAN_noise_estimate[0:512])\n",
    "            scalar_factor_noise = sum([psd_value for psd_value in GAN_noise_estimate])\n",
    "            GAN_noise_estimate_normalised = GAN_noise_estimate/scalar_factor_noise\n",
    "\n",
    "            alpha = 1\n",
    "            snr = PSD_of_windowed_signal / (100 * GAN_noise_estimate)\n",
    "            Spectral_mask = 1 - np.minimum(1, np.maximum(0, alpha * snr))\n",
    "            Clean_signal = FFT_of_windowed_signal * Spectral_mask\n",
    "            Clean_frames = np.fft.ifft(Clean_signal)\n",
    "            \n",
    "            audio_ss[0 + 128*No_of_overlaps:512 + 128*No_of_overlaps] = audio_ss[0+128*No_of_overlaps:512+128*No_of_overlaps]+ Clean_frames[0:512]\n",
    "        \n",
    "        # Save the processed audio\n",
    "        sf.write('../Spectogram/Filter_outputs/Spectral_subtract/' + str(targets[target_db]) + 'dB/' + directories[No_of_data], audio_ss, 16000, 'PCM_16')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
