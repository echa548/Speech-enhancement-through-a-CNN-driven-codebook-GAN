{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Edward\\AppData\\Roaming\\Python\\Python310\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import os\n",
    "import numpy as np\n",
    "import silence_tensorflow.auto\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import wave\n",
    "from scipy.io import wavfile\n",
    "import math\n",
    "from scipy import signal\n",
    "from pathlib import Path\n",
    "import scipy.signal as sps\n",
    "from scipy.signal import butter, lfilter\n",
    "import soundfile as sf\n",
    "import pydub\n",
    "import uuid\n",
    "from pydub import AudioSegment, effects\n",
    "from pydub.utils import make_chunks\n",
    "import random\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "import torch\n",
    "import torchaudio\n",
    "import pandas as pd\n",
    "import re\n",
    "import pathlib2\n",
    "torch.set_num_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Edward/.cache\\torch\\hub\\snakers4_silero-vad_master\n"
     ]
    }
   ],
   "source": [
    "model, utils = torch.hub.load(repo_or_dir='snakers4/silero-vad', model='silero_vad')\n",
    "(get_speech_timestamps,\n",
    " save_audio,\n",
    " read_audio,\n",
    " VADIterator,\n",
    " collect_chunks) = utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "name1 = 'dataset_va9'\n",
    "os.makedirs(name1, exist_ok=True)\n",
    "targets = [9,6,3,0,-3,-6,-9] #Change this when u add lower SNRs like: [9,6,3,0,-3,-6,-9,-12,-15,-18,-21,-24,-27,-30]\n",
    "\n",
    "for folder in range (0,len(targets)):\n",
    " directory = str(targets[folder])+'dB'\n",
    " path = os.path.join(name1,directory) \n",
    " os.makedirs(path, exist_ok=True)\n",
    "\n",
    "for folder in range (0,len(targets)):\n",
    " directory = str(targets[folder])+'dB'\n",
    " path = os.path.join(name1+'/noise',directory) \n",
    " os.makedirs(path, exist_ok=True) \n",
    "\n",
    "os.makedirs(name1+'/clean',exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Speech_dir = os.listdir('dataset_all6/clean')\n",
    "Path_to_speech = 'dataset_all6/clean'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500\n"
     ]
    }
   ],
   "source": [
    "print(len(Speech_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNR_check = np.zeros((len(Speech_dir),2))\n",
    "Segment_length_in_seconds = 0.1\n",
    "Sampling_period = 1 / 16000\n",
    "N_samples_per_seg = int(Segment_length_in_seconds / Sampling_period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target_db in range (0,len(targets)):\n",
    "  Noise_dir = os.listdir('dataset_all6/noise/'+str(targets[target_db])+'dB')\n",
    "  Path_to_noise = 'dataset_all6/noise/'+str(targets[target_db])+'dB'\n",
    "  Path_to_save = name1+'/'+str(targets[target_db])+'dB'\n",
    "  Path_to_save_for_noise = name1+'/noise/'+str(targets[target_db])+'dB'\n",
    "  SNR_target = targets[target_db]\n",
    "  for No_of_data in range (0,len(Speech_dir)):\n",
    "\n",
    "   wav = read_audio(Path_to_speech+'/'+Speech_dir[No_of_data], sampling_rate=16000)\n",
    "   \n",
    "   samplerate, Speech_data = wavfile.read(\"dataset_all6/-6dB/\"+ Speech_dir[No_of_data])\n",
    "   Bit_Check = wave.open(\"dataset_all6/-6dB/\"+ Speech_dir[No_of_data], 'rb')\n",
    "   bit_depth = Bit_Check.getsampwidth() * 8\n",
    "   Speech_data = Speech_data/(2**(bit_depth-1))\n",
    "\n",
    "   samplerate, Noise_data = wavfile.read(Path_to_noise+'/'+Noise_dir[No_of_data])\n",
    "   Bit_Check = wave.open(Path_to_noise+'/'+ Noise_dir[No_of_data], 'rb')\n",
    "   bit_depth = Bit_Check.getsampwidth() * 8\n",
    "   Noise_data = Noise_data/(2**(bit_depth-1))\n",
    "\n",
    "   Noise = read_audio(Path_to_noise+'/'+Noise_dir[No_of_data], sampling_rate = 16000)\n",
    "   speech_timestamps = get_speech_timestamps(wav, model, sampling_rate=16000)\n",
    "\n",
    "   if not(len(speech_timestamps) == 0):\n",
    "    Noise_timestamps = speech_timestamps\n",
    "    Overlapping_section_of_noise = collect_chunks(Noise_timestamps,Noise)\n",
    "    Speech_Numpy = wav.numpy()\n",
    "    Noise_Numpy = Overlapping_section_of_noise.numpy()\n",
    "    Power_of_Speech = np.sum(Speech_Numpy ** 2)\n",
    "    Power_of_Noise = np.sum(Noise_Numpy ** 2)\n",
    "\n",
    "\n",
    "    Multiple = np.sqrt(Power_of_Speech / (Power_of_Noise * (10 ** (SNR_target / 10))))\n",
    "    Noise_Numpy = Multiple * Noise_Numpy\n",
    "    Power_of_Noise = np.sum(Noise_Numpy ** 2)\n",
    "    # Print the calculated SNR to verify that it matches the target SNR\n",
    "    snr_global = 10 * np.log10(Power_of_Speech / Power_of_Noise)\n",
    "    Adjusted_noisy_speech = Speech_data+Multiple*Noise_data\n",
    "    sf.write(Path_to_save+'/'+str(Speech_dir[No_of_data]), Adjusted_noisy_speech, 16000, 'PCM_16')\n",
    "    sf.write(Path_to_save_for_noise+'/'+str(Speech_dir[No_of_data]), Multiple*Noise_data, 16000, 'PCM_16')\n",
    "\n",
    "   else:\n",
    "   \n",
    "    Speech_Numpy = wav.numpy()\n",
    "    Noise_Numpy = Noise.numpy()\n",
    "    Power_of_Speech = np.sum(Speech_Numpy ** 2)\n",
    "    Power_of_Noise = np.sum(Noise_Numpy ** 2)\n",
    "\n",
    "    Multiple = np.sqrt(Power_of_Speech / (Power_of_Noise * (10 ** (SNR_target / 10))))\n",
    "    Noise_Numpy = Multiple * Noise_Numpy\n",
    "    Power_of_Noise = np.sum(Noise_Numpy ** 2)\n",
    "     # Print the calculated SNR to verify that it matches the target SNR\n",
    "    snr_global = 10 * np.log10(Power_of_Speech / Power_of_Noise)\n",
    "    Adjusted_noisy_speech = Speech_data+Multiple*Noise_data\n",
    "    sf.write(Path_to_save+'/'+str(Speech_dir[No_of_data]), Adjusted_noisy_speech, 16000, 'PCM_16')\n",
    "    sf.write(Path_to_save_for_noise+'/'+str(Speech_dir[No_of_data]), Multiple*Noise_data, 16000, 'PCM_16')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#targets = [\"clean\", '9dB', '6dB', '3dB', '0dB', '-3dB', '-6dB', '-9dB']\n",
    "targets = [\"clean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target_db in targets:\n",
    "  Path_to_save = name1+'/'+ str(target_db)\n",
    "  Path_to_speech = 'dataset_all6/'+ str(target_db)\n",
    "\n",
    "  for No_of_data in range (0,len(Speech_dir)):\n",
    "    wav = read_audio(Path_to_speech + '/'+ Speech_dir[No_of_data], sampling_rate=16000)\n",
    "\n",
    "    samplerate, Speech_data = wavfile.read(Path_to_speech + '/' + Speech_dir[No_of_data])\n",
    "    Bit_Check = wave.open(Path_to_speech + '/' + Speech_dir[No_of_data], 'rb')\n",
    "    bit_depth = Bit_Check.getsampwidth() * 8\n",
    "    Speech_data = Speech_data/(2**(bit_depth-1))\n",
    "\n",
    "    speech_timestamps = get_speech_timestamps(wav, model, sampling_rate=16000)\n",
    "    if not(len(speech_timestamps) == 0):\n",
    "      Speech_filtered_by_VAD = collect_chunks(speech_timestamps, wav)\n",
    "      Speech_Numpy = Speech_filtered_by_VAD.numpy()\n",
    "\n",
    "      sf.write(Path_to_save+'/'+str(Speech_dir[No_of_data]), Speech_Numpy, 16000, 'PCM_16')\n",
    "\n",
    "    else:\n",
    "\n",
    "      Speech_Numpy = wav.numpy()\n",
    "      sf.write(Path_to_save+'/'+str(Speech_dir[No_of_data]), Speech_Numpy, 16000, 'PCM_16')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
