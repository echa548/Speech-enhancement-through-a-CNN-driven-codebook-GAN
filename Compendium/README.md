# Part 4 Project Group 58

## The reconstruction of speech/voice with the use of noise-cancelling algorithms and machine learning

Team members: Edward Chan and Timothy Aguana Cabrera

Abstract: This contribution addresses enhancing speech quality in noisy environments with low signal-to-noise ratios (SNR). The approach consists of two key components. First, it leverages codebooks derived from Gaussian mixture models (GMMs) and a Wasserstein Generative Adversarial Network (WGAN) to generate time-varying spectral candidates that closely resemble noise spectra. While the estimation of noise spectra is accurate, the estimation of speech spectra needs to improve, resulting in distorted and unintelligible Wiener-filtered mixtures.
Low SNR leads to significantly quieter speech, posing a problem in the realm of audio signal processing. To tackle this issue, the paper proposes an iterative learning approach that combines two machine learning algorithms for speech enhancement and classification in noisy mixtures. The first algorithm employs a WGAN for end-to-end learning to generate noise spectra that can be used to create enhanced speech. Simultaneously, considering SNR levels, a convolutional neural network (CNN) uses the spectrogram representation of the estimated clean speech to classify between clean and noisy speech.
The primary objective of this paper is to explore whether improvement to the performance of the codebook-based approach can be used with SNR levels to indicate improved speech quality and intelligibility. To evaluate the algorithm's performance, the proposed method utilises computational matrices, including perceptual evaluation of speech (PESQ), short-time objective intelligibility (STOI), and signal distortion ratio (SDR).

## Structure
The repository has the following structure
- [Creating-Dataset](Creating-Dataset): Contains a Python program used to generate the dataset to train and test models
- [Dataset](Dataset): Where the training dataset is generated after using [Creating-Dataset](Creating-Dataset) and where evaluation WAV files should be placed
- [Evaluation](Evaluation): Contains a Python program used to perform speech enhancement and generate the evaluation of one or more audio WAV files
- [Exhibition-Day-Presentation](Exhibition-Day-Presentation): Contains the exhibition presentation and poster
- [Models-Setup](Models-Setup): Contains Python code for training both the GAN and the CNN models
- [Models](Models): Where models generated by [Models-Setup](Models-Setup) are kept and loaded from
- [Others](Others): Stores progression documentation, presentation and flowcharts
- [Project-Compendium-Report](Project-Compendium-Report): Contains the report of the overall compendium
- [Results](Results): CNN classification results, GAN results and the overall system evaluation results
- [Seminar-Presentation](Seminar-Presentation): The presentation slides for the mid-year seminar

## Getting Started
1. Install Python version 3.8.0
2. Clone the repository
3. Run `pip install -r requirements.txt` in terminal (use correct cloned directory to install required packages)

## Packages
We used Python version 3.8.0 and we used pip version 23.2.1
The packages that we used:
| Package Name | Version |
| --- | --- |
| Torch | 2.0.1 |
| Torchaudio | 2.0.2 |
| Librosa | 0.10.1 |
| Scipy | 1.10.1 |
| Numpy | 1.23.4 |
| Pydub| 0.25.1 |
| Soundfile | 0.12.1 |
| Openpyxl | 3.1.2 |
| Xlsxwriter | 3.1.2|
| Matplotlib | 3.7.2 |
| Tensorflow | 2.8.0 |
| Keras | 2.8.0 |
| Scikit-learn | 1.3.0 |
| Seaborn | 0.12.2 |
| Pesq | 0.0.4 |
| Pystoi | 0.3.3 |
| Mir_eval | 0.7 |


## Setup

### Creating Dataset
- Go to [Creating-Dataset](Creating-Dataset)
- Open create-dataset.ipynb
- Download the [speech dataset](https://www.kaggle.com/datasets/showmik50/vctk-dataset) and [noise dataset](https://www.kaggle.com/datasets/chrisfilo/demand)
- Extract these folders place them in [Creating-Dataset](Creating-Dataset) (Create a new folder called "noisy" and extract the noisy dataset in the folder)
- In Step 5 change the number of samples to create to you desired value `n = 1500`
- Then Run All

### Generating CNN Classification Model
- Go to [Classification-Setup](Models-Setup/Classification-Setup)
- Open class_model.ipynb
- In Step 4 change the batch_size and epoch number to your desired value `batch_size=10, epochs=20`
- Change model name in Step 6 to your desired name `model.save(model_path + 'my_model.h5')`
- Run from Step 1 to Step 6 to save model (Step 7 loads the model and predicts the SNR levels for all WAV files in `path_test_dataset = "../../Dataset/predict_dataset/"`)

### Generating GAN Speech Enhancement Model
- Go to [GAN-Setup](Models-Setup/GAN-Setup). Important!! Run this using an IDE. Comments are left in the files regarding directories and functionality!!
- After the steps outlines in Creating Dataset, run the Silero-VAD file to apply VAD SNR. This will generate a new audio files in Dataset/VAD_SNR.
- After the new audio files have been created in (Dataset/VAD_SNR), please copy paste the folder containing clean speech from (Dataset/dataset) to (Dataset/VAD_SNR)
- To prepare the data for the WGAN go to [GAN-Setup](Models-Setup/GAN-Setup) and run both Generate_Noise_PSDs and Generate_Speech_PSDs. This will create npy files with data. Adjust segments desired.
- After data creation, run the Noise-WGAN-GP-model and Noise-WGAN-GP-models. Models are saved in (Models/GAN-Models). Modify save intervals/batch size as required.

### Gaussian Mixture Modelling
- Go to [GMM-Setup](Models-Setup/GMM-Setup)
- After the initial dataset made by create-dataset.ipynb is created, run the VAD_Merge. Important!! Run this using an IDE. Comments are left in the files regarding directories and functionality!!
- After the step above, derive the codebooks by running the GMM_Codebook Python script.

### Perform Evaluation
- Go to [Evaluation](Evaluation)
- Open performing_evaluation.ipynb
- If need be change directory for CNN model in Step 1 `cnn_model = tf.keras.models.load_model('../Models/Classification Models/my_model.h5')`
- If need be change directory for GAN model in Step 1 `Noise_gan = tf.saved_model.load('../Models/GAN Models/Full_Curriculum_4_generator')`
- You can also change the directory for where the evaluation is saved in Step 3 `path_eval = "Evaluation1"`
- Run Step 1 to 3 to create a directory for where the evaluation will be performed
- With the directory created add your desired noisy mixture and clean speech to folders in `path_eval = "Evaluation1"` named `clean_path = path_eval + "/clean"` and `noisy_path = path_eval + "/noisy"`
- Make sure the name of the audio added is speech_"number".WAV the same as the create_dataset convention (With the text inside "" being changed to a number)
- Run Step 4

## Results
CNN classification [results](Result/CNN-classification-results).

GAN speech enhancement [results](Result/GAN-results).

To generate the evaluation results and enhanced speech use [performing_evaluation.ipynb](Evaluation). Our results using the default settings of the CNN and GAN models outputted these [Results](Result/Overall-system-results).

## Future Improvements

## Key Notes
- We created this program using Windows 10

## Acknowledgement
We want to thank the supervisor, Catherine Watson, and co-supervisor, Yusuke Hioka, for providing the support and guidelines to make this project successful.
