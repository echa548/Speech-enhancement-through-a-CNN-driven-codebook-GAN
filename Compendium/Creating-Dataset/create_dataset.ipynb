{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the speech and noise dataset from DEMAND and VCTK\n",
    "- The file extraction is based on these two dataset if there is a change in dataset make sure the change the directory names\n",
    "- This program can be used to generate both training and testing datasets for both the GAN and CNN models.\n",
    "\n",
    "https://www.kaggle.com/datasets/showmik50/vctk-dataset\n",
    "You can extract the vctk dataset directly in the same folder as the create_dataset.ipynb\n",
    "\n",
    "https://www.kaggle.com/datasets/chrisfilo/demand\n",
    "Extract the demand dataset inside of a new folder called \"noise\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1+cpu\n",
      "2.0.2+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.functional as F\n",
    "import math\n",
    "import librosa\n",
    "import wave\n",
    "import os\n",
    "import shutil\n",
    "from scipy.io import wavfile\n",
    "import math\n",
    "import numpy as np\n",
    "import scipy.signal as sps\n",
    "from scipy.signal import butter, lfilter\n",
    "import random\n",
    "from pydub import AudioSegment, effects\n",
    "import soundfile as sf\n",
    "import openpyxl\n",
    "\n",
    "import xlsxwriter\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchaudio.__version__)\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1) Creating folders for mixtures at different SNR levels and including the original clean and noisy speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataset folder and sub-folders\n",
    "folder_name = \"../Dataset/dataset\" # change to change dataset name and directory if needed\n",
    "path_clean = folder_name + \"/clean/\"\n",
    "path_noisy = folder_name + \"/noisy/\"\n",
    "path_0dB = folder_name + \"/0dB/\"\n",
    "path_n3dB = folder_name + \"/-3dB/\"\n",
    "path_n6dB = folder_name + \"/-6dB/\"\n",
    "path_n9dB = folder_name + \"/-9dB/\"\n",
    "path_3dB = folder_name + \"/3dB/\"\n",
    "path_6dB = folder_name + \"/6dB/\"\n",
    "path_9dB = folder_name + \"/9dB/\"\n",
    "path_noise = folder_name + \"/new_noise/\" # Segement of the orignal noise\n",
    "path3 = folder_name + \"/all_info.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the %s directory is created! ../Dataset/predict_dataset\n",
      "the %s directory is created! ../Dataset/predict_dataset\n",
      "The excel file 1 is created!\n"
     ]
    }
   ],
   "source": [
    "isExist = os.path.exists(folder_name)\n",
    "if not isExist:\n",
    "   # Create a new directory because it does not exist\n",
    "   os.makedirs(folder_name)\n",
    "   os.makedirs(folder_name + \"/clean\")\n",
    "   os.makedirs(folder_name + \"/noisy\")\n",
    "   os.makedirs(folder_name + \"/0dB\")\n",
    "   os.makedirs(folder_name + \"/-3dB\")\n",
    "   os.makedirs(folder_name + \"/-6dB\")\n",
    "   os.makedirs(folder_name + \"/-9dB\")\n",
    "   os.makedirs(folder_name + \"/3dB\")\n",
    "   os.makedirs(folder_name + \"/6dB\")\n",
    "   os.makedirs(folder_name + \"/9dB\")\n",
    "   print(\"the %s directory is created!\", folder_name)\n",
    "\n",
    "isExist2 = os.path.exists(path_noise)\n",
    "if not isExist:\n",
    "   # Create a new directory because it does not exist\n",
    "   os.makedirs(path_noise)\n",
    "   os.makedirs(path_noise + \"/0dB\")\n",
    "   os.makedirs(path_noise + \"/-3dB\")\n",
    "   os.makedirs(path_noise + \"/-6dB\")\n",
    "   os.makedirs(path_noise + \"/-9dB\")\n",
    "   os.makedirs(path_noise + \"/3dB\")\n",
    "   os.makedirs(path_noise + \"/6dB\")\n",
    "   os.makedirs(path_noise + \"/9dB\")\n",
    "   print(\"the %s directory is created!\", folder_name)\n",
    "\n",
    "isExist3 = os.path.exists(path3)\n",
    "if not isExist3:\n",
    "   workbook1 = xlsxwriter.Workbook(path3)\n",
    "   worksheet1 = workbook1.add_worksheet()\n",
    "   worksheet1.write(0, 0, \"Sample Number\")\n",
    "   worksheet1.write(0, 1, \"Name\")\n",
    "   worksheet1.write(0, 2, \"Length(s)\")\n",
    "   worksheet1.write(0, 3, \"Type of Speech\")\n",
    "   worksheet1.write(0, 4, \"SNR(dB)\")\n",
    "   worksheet1.write(0, 5, \"Noise Type\")\n",
    "   worksheet1.write(0, 6, \"Noise Channel\")\n",
    "   worksheet1.write(0, 7, \"Speaker ID\")\n",
    "   worksheet1.write(0, 8, \"Passage ID\")\n",
    "   worksheet1.write(0, 9, \"Noise Start Time(s)\")\n",
    "   print(\"The excel file 1 is created!\")\n",
    "   workbook1.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2) Locations of speech and noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of speech folders: 109\n"
     ]
    }
   ],
   "source": [
    "speech_fpath = \"VCTK-Corpus/VCTK-Corpus/wav48/\" # Change this for different speech dataset\n",
    "speech_file_entries = os.listdir(speech_fpath)\n",
    "print(\"Amount of speech folders: \" + str(len(speech_file_entries)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of noise folders: 17\n"
     ]
    }
   ],
   "source": [
    "noise_fpath = \"noise/\" # Change this for different noise dataset \n",
    "\n",
    "# List all items (files and directories) in the specified directory - Specific for the demand dataset to remove the 48k noise\n",
    "items = os.listdir(noise_fpath)\n",
    "# Iterate through the items and remove folders with \"48K\" in their names\n",
    "for item in items:\n",
    "    item_path = os.path.join(noise_fpath, item)\n",
    "    \n",
    "    if os.path.isdir(item_path) and \"48k\" in item.split(\"_\")[1]:\n",
    "        try:\n",
    "            shutil.rmtree(item_path)  # Use os.rmdir to remove directories\n",
    "            print(f\"Removed: {item}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error removing {item}: {e}\")\n",
    "noise_file_entries = os.listdir(noise_fpath)\n",
    "print(\"Amount of noise folders: \" + str(len(noise_file_entries)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3) Normalise and downsample speech from 48K to 16K and normalise noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_lowpass(cutoff, fs, order=5): # Butterworth lowpass filter\n",
    "    return butter(order, cutoff, fs=fs, btype='low', analog=False)\n",
    "\n",
    "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
    "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsampling(clip): # Downsample the audio to 16k\n",
    "    samplerate, data = wavfile.read(clip)\n",
    "    Fs1 = samplerate\n",
    "    Fs2 = 16000\n",
    "    N = len(data)\n",
    "    total_time = (N-1)/Fs1\n",
    "    Max_Signal_Frequency =Fs2/2\n",
    "    New_sample_amount = math.ceil(Fs2*total_time)\n",
    "    Single_Channel = np.zeros(New_sample_amount)\n",
    "    Bit_Check = wave.open(clip) # Check the bit depth of the audio\n",
    "    bit_depth = Bit_Check.getsampwidth() * 8\n",
    "    data = data/(2**(bit_depth-1))\n",
    "    Original_signal = data\n",
    "    Anti_Aliased_signal = np.array(butter_lowpass_filter(Original_signal,Max_Signal_Frequency,Fs1))\n",
    "    Down_sampled_signal = np.array(sps.resample(Anti_Aliased_signal,New_sample_amount))\n",
    "    Single_Channel = Down_sampled_signal\n",
    "    Transformed_single_channel = Single_Channel.transpose()\n",
    "    return Transformed_single_channel, Fs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(inclip, outclip): # Normalise the audio\n",
    "    rawsound = AudioSegment.from_wav(inclip)  \n",
    "    normalizedsound = effects.normalize(rawsound)  \n",
    "    normalizedsound.export(outclip, format = 'wav')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4) Adding noise to speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adding_noise_to_speech(speech, noise, i):\n",
    "    speech, _ = torchaudio.load(speech)\n",
    "    noise, _ = torchaudio.load(noise)\n",
    "\n",
    "    # From a random point in the noise waveform make the size of the noise the same as the speech\n",
    "    first = random.randint(0, noise.shape[1] - speech.shape[1])\n",
    "    noise = noise[:, first:first + speech.shape[1]]\n",
    "\n",
    "    # Calculate the time range of the noise in minutes\n",
    "    noise_start_time = first / 16000\n",
    "    # At all SNR levels add the noise to the speech\n",
    "    snr_dbs = torch.tensor([0, -3, -6, -9, 3, 6, 9], device=device)\n",
    "    noisy_speeches = F.add_noise(speech.to(device), noise.to(device), snr_dbs)\n",
    "\n",
    "    snr_db, noisy_speech = snr_dbs[0].item(), noisy_speeches[0:1]\n",
    "    torchaudio.save(path_0dB + \"speech_\" + str(i) + \".wav\", noisy_speech.cpu(), 16000, encoding=\"PCM_S\", bits_per_sample=16)\n",
    "\n",
    "    snr_db, noisy_speech = snr_dbs[1].item(), noisy_speeches[1:2]\n",
    "    torchaudio.save(path_n3dB + \"speech_\" + str(i) + \".wav\", noisy_speech.cpu(), 16000, encoding=\"PCM_S\", bits_per_sample=16)\n",
    "\n",
    "    snr_db, noisy_speech = snr_dbs[2].item(), noisy_speeches[2:3]\n",
    "    torchaudio.save(path_n6dB + \"speech_\" + str(i) + \".wav\", noisy_speech.cpu(), 16000, encoding=\"PCM_S\", bits_per_sample=16)\n",
    "\n",
    "    snr_db, noisy_speech = snr_dbs[3].item(), noisy_speeches[3:4]\n",
    "    torchaudio.save(path_n9dB + \"speech_\" + str(i) + \".wav\", noisy_speech.cpu(), 16000, encoding=\"PCM_S\", bits_per_sample=16)\n",
    "\n",
    "    snr_db, noisy_speech = snr_dbs[4].item(), noisy_speeches[4:5]\n",
    "    torchaudio.save(path_3dB + \"speech_\" + str(i)+ \".wav\", noisy_speech.cpu(), 16000, encoding=\"PCM_S\", bits_per_sample=16)\n",
    "\n",
    "    snr_db, noisy_speech = snr_dbs[5].item(), noisy_speeches[5:6]\n",
    "    torchaudio.save(path_6dB + \"speech_\" + str(i) + \".wav\", noisy_speech.cpu(), 16000, encoding=\"PCM_S\", bits_per_sample=16)\n",
    "\n",
    "    snr_db, noisy_speech = snr_dbs[6].item(), noisy_speeches[6:7]\n",
    "    torchaudio.save(path_9dB + \"speech_\" + str(i) + \".wav\", noisy_speech.cpu(), 16000, encoding=\"PCM_S\", bits_per_sample=16)\n",
    "\n",
    "    # Save the noisy speech at different SNR levels\n",
    "    for j, snr_db in enumerate(snr_dbs):\n",
    "        snr_db = snr_db.item()\n",
    "        noisy_speech = noisy_speeches[j:j+1]\n",
    "        # Save the noise separately at each SNR level\n",
    "        noise_at_snr = noisy_speech - speech.to(device)\n",
    "        torchaudio.save(path_noise + \"/\" + str(snr_db) + \"dB/speech_\" + str(i) + \".wav\", noise_at_snr.cpu(), 16000, encoding=\"PCM_S\", bits_per_sample=16)\n",
    "        \n",
    "    return noise_start_time\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5) Create all and classification data with excel information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 50 noisy file: NFIELD_16k clean file: p256 duration: 7.47 secondsds\r"
     ]
    }
   ],
   "source": [
    "n = 1500 # Change the number of samples created\n",
    "for i in range (0, n):\n",
    "\n",
    "    # Random number to select the clean speech file (speaker) used\n",
    "    ran_1 = random.randrange(0, len(speech_file_entries) - 1)\n",
    "    speech_file = speech_file_entries[ran_1]\n",
    "    speech_enter = speech_fpath + speech_file + \"/\"\n",
    "    speech_entries = os.listdir(speech_enter)\n",
    "\n",
    "    # Random number to select the passage used\n",
    "    ran_2 = random.randrange(0, len(speech_entries) - 1)\n",
    "    select_speech = speech_enter + speech_entries[ran_2]\n",
    "\n",
    "    # Selecting the noise\n",
    "    ran_3 = random.randrange(0, len(noise_file_entries) - 1)\n",
    "    noise_file = noise_file_entries[ran_3]\n",
    "    noise_enter = noise_fpath + noise_file + \"/\" + noise_file.split(\"_\")[0] + \"/\"\n",
    "    noise_entries = os.listdir(noise_enter)\n",
    "\n",
    "    # Random number to select the channel used\n",
    "    ran_4 = random.randrange(0, len(noise_entries) - 1)\n",
    "    select_noise = noise_enter + noise_entries[ran_4]\n",
    "\n",
    "    # downsampling then normalising the clean speech\n",
    "    data, samplerate = downsampling(select_speech)\n",
    "    sf.write(path_clean + \"speech_\" + str(i + 1) + \".wav\", data, samplerate, 'PCM_16')\n",
    "    normalise(path_clean + \"speech_\" + str(i + 1) + \".wav\", path_clean + \"speech_\" + str(i + 1) + \".wav\")\n",
    "    \n",
    "    # normalising the noisy speech\n",
    "    normalise(select_noise, path_noisy + \"noisy_\" + str(i + 1) + \".wav\")\n",
    "\n",
    "    # Combinding the clean speech and the noise\n",
    "    noise_start_time = adding_noise_to_speech(path_clean + \"speech_\" + str(i + 1) + \".wav\", path_noisy + \"noisy_\" + str(i + 1) + \".wav\", i + 1)\n",
    "\n",
    "    # Adding the information to the excel file\n",
    "    duration = round(librosa.get_duration(path=select_speech), 2) # Duration of speech\n",
    "    passage_ID = speech_entries[ran_2].split('.')[0].split('_')[1] # Passage ID\n",
    "    noise_channel = noise_entries[ran_4].split('.')[0]# Noise channel\n",
    "\n",
    "    workfile1 = openpyxl.load_workbook(path3)\n",
    "\n",
    "    sheet1 = workfile1.active\n",
    "\n",
    "    sheet1.cell(row=i+2, column=1).value = i+1\n",
    "    sheet1.cell(row=i+2, column=2).value = \"speech_\" + str(i + 1) + \".wav\"\n",
    "    sheet1.cell(row=i+2, column=3).value = duration\n",
    "    sheet1.cell(row=i+2, column=4).value = \"noisy | clean\"\n",
    "    sheet1.cell(row=i+2, column=5).value = \"0 | -3 | -6 | -9 | 3 | 6 | 9\"\n",
    "    sheet1.cell(row=i+2, column=6).value = noise_file\n",
    "    sheet1.cell(row=i+2, column=7).value = noise_channel\n",
    "    sheet1.cell(row=i+2, column=8).value = speech_file\n",
    "    sheet1.cell(row=i+2, column=9).value = passage_ID\n",
    "    sheet1.cell(row=i+2, column=10).value = noise_start_time\n",
    "\n",
    "    workfile1.save(path3)\n",
    "\n",
    "    file_path = select_speech\n",
    "\n",
    "    # Check if the file exists\n",
    "    if os.path.exists(file_path):\n",
    "        # Delete the file\n",
    "        os.remove(file_path)\n",
    "\n",
    "    # Update the user\n",
    "    print(\"iteration: \" + str(i + 1) + \" noisy file: \" + noise_file + \" clean file: \" + speech_file + \" duration: \" + str(duration) + \" seconds\", end = \"\\r\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
